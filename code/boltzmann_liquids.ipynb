{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TyMfirtsrai5",
        "oLBzUby_eD0V",
        "4RNa3LQqb1Zl",
        "MQTF3t6vybLN",
        "JF9e1Yxp4Bwi",
        "CdDfihX8ynFN",
        "fCuEZGW0Y3Kc",
        "n4At_hoTY-kA",
        "vqrRAO7Wizz8",
        "WAGQBrQ8mFwQ",
        "HLyL9v7hl06n",
        "wM77zaaCCsQt",
        "nz-vpFV8Ajtj",
        "3jGGNvVUGwec",
        "8RAHBtNSIKn5",
        "tywe2VK6bBA8",
        "aMgpN7u6jSVo",
        "6Ofp-wFKgyYS",
        "L7QS2LSeq4nX",
        "WGxncIw7DCgs",
        "ZMeQpKHv4h7l",
        "XZL9_p9z6AUQ",
        "OakHgMgwCP0M",
        "wcSLQZJjMwz2",
        "g7j5twj8wOfu",
        "Cc_LF0CJ2-Zl",
        "RrKmlQ2ZkOBm",
        "38DO1KfG5TER",
        "GcM9ep436LQa",
        "H_a4dXvh6qbw",
        "yDKVPsAQboc6",
        "E0PKuLdx5k2N",
        "GJa1EMOncVgM",
        "EAOr9bwfysZ4",
        "mPayxz1L-Lgh",
        "zGSke1qPKPza"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Learning and Inference in a Lattice Model of Multicomponent Condensates**\n",
        "\n",
        "Author: Cameron Chalk\n",
        "\n",
        "This notebook recreates experiments using new backend code with improved speed and readability. The notebook is terse but should be explained sufficiently by the paper (https://doi.org/10.4230/LIPIcs.DNA.30.1). Parameters used for the results shown in the paper are included and can be further tested.\n",
        "\n",
        "**USAGE:** Import the boltzmann_liquids_cuda.py from the Github code folder directly into the Colab files directory (or in the same directory as this .ipynb if you are running locally). Run the initialization section first. Each other section should be run \"atomically\", in the sense that the sections are not atomic, i.e. they share variable names, so that running the Hopfield condensation section after running the Avocado section will overwrite some of your Avocado variables.\n",
        "\n",
        "**DATA:** If you wish to use the paper-reported $G_{i,j}$, $G_i$, or the pre-processed MNIST data, import the data from the Github directly (not as a folder) into the Colab files directory (or in the same directory as this .ipynb if you are running locally).\n",
        "\n",
        "**IMPORTANT: DOCUMENTATION FOR THE MAIN MCMC FUNCTION:** Most of the notebook is standard Python/numpy/matplotlib code. Here, for convenience, I will paste the documentation for the mcmc() function from the boltzmann_liquids_cuda.py, since it is essentially the only non-Python/numpy/matplotlib function used. Thus it is important to read this carefully:\n",
        "\n",
        "    GPU-accelerated Metropolis-Hastings MCMC for the 3D lattice Boltzmann liquid model.\n",
        "\n",
        "        This is a wrapper around several Numba-CUDA kernels. Each lattice in `lattice_batch`\n",
        "        is simulated independently, with one CUDA block per lattice.\n",
        "        Arguments called \"*_batch\", if passed as a list of arguments of length equal\n",
        "        to the number of lattices given by lattice_batch,\n",
        "        will be used in each lattice (i.e., if a list of g_ij matrices are given,\n",
        "        then the nth lattice in the batch will use the nth g_ij matrix).\n",
        "        All arguments called \"*_batch\" can also be passed in as singletons\n",
        "        (i.e., a single lattice and a single g_ij; or, a list of lattices\n",
        "        can be passed in along with a single g_ij matrix and each lattice\n",
        "        will use the single g_ij matrix.)\n",
        "        Within a kernel launch,\n",
        "        the block runs many proposal steps without returning to the CPU. After burn-in, the\n",
        "        wrapper advances the chain between samples, copies the lattice(s) back to host, and\n",
        "        accumulates summary statistics (n_ij, n_i, energies).\n",
        "        A save_lattices option allows the return of all sampled lattice configurations,\n",
        "        instead of (by default) the single endpoint lattice configuration(s).\n",
        "\n",
        "        Model and energy\n",
        "        ----------------\n",
        "        - Lattice sites store integer species IDs in [0, num_species-1].\n",
        "        - Pairwise interaction energies are given by `g_ij` (symmetric).\n",
        "        - Optional per-species energies are given by `g_i`.\n",
        "        - The Metropolis accept probability uses:  min(1, exp(-ΔE / kT)).\n",
        "\n",
        "        Update modes (kernel choice)\n",
        "        ----------------------------\n",
        "        Exactly one mode is used per call:\n",
        "        - Grand-canonical (default): single-site resampling (site chooses a random new species).\n",
        "        Uses a **checkerboard** update to avoid simultaneously updating interacting neighbors.\n",
        "        - Canonical local swaps (canonical=True): swap species between two sites.\n",
        "        Uses a **mod-4 sublattice** scheme to keep simultaneous swaps disjoint.\n",
        "        - Canonical ranged swaps (canonical=True, ranged=True): long-range swaps between\n",
        "        mod-4 sublattices plus a small displacement from `swap_directions`.\n",
        "        - Hybrid (hybrid=True): randomly mixes GC steps and ranged-swap steps *inside the kernel*.\n",
        "\n",
        "        Important: if `canonical=True`, it takes precedence over `hybrid=True` (hybrid is ignored).\n",
        "\n",
        "        Temperature / annealing\n",
        "        -----------------------\n",
        "        Burn-in is run as a single kernel launch of `burn_in` proposals with geometric annealing:\n",
        "        kT : kT_high_batch -> kt_low_batch over `burn_in` steps (if different).\n",
        "        During sampling, each inter-sample advance runs at constant temperature kt_low_batch\n",
        "        (the wrapper passes kT_high = kT_low for those kernel calls).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        lattice_batch : array-like (int32)\n",
        "            Either a single lattice of shape (H, W, L) or a batch of lattices of shape\n",
        "            (B, H, W, L). All lattices are assumed to have the same shape.\n",
        "            H, W, and L must each be multiples of 4.\n",
        "\n",
        "        num_parallel_proposals : int\n",
        "            A budget used to compute the inter-sample spacing:\n",
        "                sample_rate = (num_parallel_proposals - burn_in) // num_samples\n",
        "            The actual number of proposals performed is:\n",
        "                burn_in + num_samples * sample_rate\n",
        "            (This is <= num_parallel_proposals due to floor division.)\n",
        "\n",
        "        num_samples : int\n",
        "            Number of samples to collect after burn-in.\n",
        "\n",
        "        burn_in : int\n",
        "            Number of proposal steps during burn-in (annealed from kT_high to kT_low if provided).\n",
        "\n",
        "        num_species : int\n",
        "            Number of species. Lattice entries must be valid indices: 0 <= s < num_species.\n",
        "\n",
        "        g_ij_batch : array-like (float)\n",
        "            Pairwise interaction energies. Accepts shape (num_species, num_species) or\n",
        "            (B, num_species, num_species). For correctness with the swap kernels, `g_ij`\n",
        "            is expected to represent symmetric interactions (g_ij[i,j] == g_ij[j,i]).\n",
        "\n",
        "        g_i_batch : array-like (float), optional\n",
        "            Per-species energies. Shape (num_species,) or (B, num_species). If omitted, zeros.\n",
        "            Used by GC updates (and for reported energies). In canonical modes, counts are fixed,\n",
        "            so `g_i` does not affect acceptance, but it is still included in configuration energy.\n",
        "\n",
        "        kT_batch : float or array-like (float), optional\n",
        "            Convenience temperature input. If provided and kT_high_batch/kt_low_batch are not,\n",
        "            the wrapper sets kT_high = kT_low = kT_batch (i.e., constant temperature).\n",
        "\n",
        "        kT_high_batch, kT_low_batch : float or array-like (float), optional\n",
        "            Burn-in annealing endpoints. Each may be scalar or length-B. If neither is provided,\n",
        "            both default to 1.0.\n",
        "\n",
        "        free_pos_batch : array-like (bool/int), optional\n",
        "            Mask of free (updatable) lattice positions. True/1 = free, False/0 = clamped.\n",
        "            Accepts shape (H, W, L) or (B, H, W, L). If omitted, all positions are free.\n",
        "\n",
        "        free_species_batch : array-like (int), optional\n",
        "            Mask of free species IDs, used only in GC (and GC part of hybrid):\n",
        "            proposals that would change to or from a non-free species are suppressed.\n",
        "            Shape (num_species,) or (B, num_species). If omitted, all species are free.\n",
        "\n",
        "        periodic : bool\n",
        "            Boundary condition for local energy evaluation and neighbor addressing.\n",
        "            - In the non-ranged canonical case, False here does prevent periodic swap proposals.\n",
        "\n",
        "        canonical : bool\n",
        "            If True, use canonical swap updates instead of GC resampling.\n",
        "\n",
        "        ranged : bool\n",
        "            Only used if canonical=True. If True, use ranged-swap kernel; else local-swap kernel.\n",
        "\n",
        "        hybrid : bool\n",
        "            If True (and canonical=False), use the hybrid kernel (randomly mixes GC and ranged steps).\n",
        "\n",
        "        neighbor_displacements : tuple/list of (dx, dy, dz)\n",
        "            Defines the neighborhood used in energy calculations.\n",
        "            Constraints for correctness / detailed balance with the parallel update schemes:\n",
        "            - GC mode: must be von Neumann (DEFAULT_NEIGHBOR_DISPLACEMENTS). Using Moore\n",
        "            or larger neighborhoods causes race conditions which (probably) break detailed balance.\n",
        "            - Canonical modes: must be a subset of the Moore neighborhood (dx,dy,dz ∈ {-1,0,1})\n",
        "            to prevent race conditions. In short, for an extended neighborhood, proposals must be\n",
        "            changed to a mod-k sublattice scheme (it is currently hardcoded mod-4).\n",
        "\n",
        "        swap_directions : tuple/list of (dx, dy, dz)\n",
        "            Possible displacements for swap proposals in canonical kernels.\n",
        "            Must be a subset of the Moore neighborhood (dx,dy,dz ∈ {-1,0,1}) to prevent\n",
        "            races/overlapping swaps under the mod-4 sublattice scheme.\n",
        "\n",
        "        seed : int, optional\n",
        "            RNG seed for xoroshiro128p states (ignored if `rng_states` is provided).\n",
        "\n",
        "        save_lattices : bool\n",
        "            If True, returns a list of sampled lattice configurations (host copies).\n",
        "\n",
        "        rng_states : numba.cuda.random.Xoroshiro128pStates, optional\n",
        "            Pre-initialized RNG states. Must have length:\n",
        "                THREADS_PER_BLOCK_1D * num_lattices\n",
        "            (One RNG stream per thread across all blocks.)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        If save_lattices is False:\n",
        "            lattice_final, avg_n_ij, avg_n_i, energies_list\n",
        "\n",
        "        If save_lattices is True:\n",
        "            saved_lattices, avg_n_ij, avg_n_i, energies_list\n",
        "\n",
        "        Where:\n",
        "        - lattice_final:\n",
        "            Final lattice configuration(s), shape (H,W,L) if B=1 else (B,H,W,L).\n",
        "            (Note: `saved_lattices` entries are not squeezed even when B=1.)\n",
        "        - avg_n_ij:\n",
        "            Sample-mean interaction counts. Shape (num_species,num_species) if B=1 else\n",
        "            (B,num_species,num_species).\n",
        "        - avg_n_i:\n",
        "            Sample-mean species counts. Shape (num_species,) if B=1 else (B,num_species).\n",
        "        - energies_list:\n",
        "            Energies for bookkeeping, shape (num_samples+1,) if B=1 else (B,num_samples+1).\n",
        "            energies_list[..., 0] is computed from the **initial** configuration (pre-burn-in);\n",
        "            energies during burn-in are not recorded.\n",
        "\n",
        "        Critical reminders\n",
        "        ------------------------------\n",
        "        - Canonical modes require lattice dimensions H, W, L to be multiples of 4.\n",
        "        (The mod-4 offset scheme can otherwise index beyond lattice bounds.)\n",
        "        - Ensure `num_parallel_proposals > burn_in` and that\n",
        "            (num_parallel_proposals - burn_in) // num_samples >= 1\n",
        "        or else sample_rate may be 0 (yielding repeated identical samples).\n",
        "        - All lattices in the batch must share the same shape.\n",
        "\n",
        "Unfortunately, exact recreation of the experiments (e.g., using identical RNG seeds) is not possible (or at least, not easy) due to changes in the backend code. Please alert ctchalk2@gmail.com about any discrepancies, as they may reflect errors in either the old backend or new backend code. The new backend code has been tested more thoroughly and so is more likely to be correct (although I believe both are correct, and I have yet to find any discrepancies).\n",
        "\n",
        "Important erratum: The paper reports that all simulations employed non-periodic boundary conditions. However, the training and unclamped testing of the avocado interaction energies for the paper were done using periodic boundary conditions, as is the case in the notebook below."
      ],
      "metadata": {
        "id": "TyMfirtsrai5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IMPORTANT:\n",
        "The code here was needed to get the Numba CUDA code to work with the default Colab Runtime version (this was written 1/28/2026; I can't find the name of the Runtime version). You can test with and without running this configuration code. My guess is, for some Runtime version of the future, the code will work whether you run this or not. Alternatively, Numba CUDA support could become deprecated. If that's the case, you'd need to rewrite boltzmann_liquids_cuda.py in standard C++ CUDA."
      ],
      "metadata": {
        "id": "oLBzUby_eD0V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5QV5v-9rQSg"
      },
      "outputs": [],
      "source": [
        "from numba import config\n",
        "config.CUDA_ENABLE_PYNVJITLINK = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Initialization (run these first, no matter which section you'd like to run)"
      ],
      "metadata": {
        "id": "4RNa3LQqb1Zl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Imports"
      ],
      "metadata": {
        "id": "phrl0KqCxx9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import logsumexp\n",
        "from itertools import product\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import matplotlib.colors as mplcolors\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.patheffects as pe\n",
        "\n",
        "from boltzmann_liquids_cuda import (\n",
        "    get_n_ij, get_n_i, config_energy, mcmc\n",
        ")\n",
        "\n",
        "print(\"All imports successful\")"
      ],
      "metadata": {
        "id": "-YY3LbZDxesv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visualization/plotting functions"
      ],
      "metadata": {
        "id": "MQTF3t6vybLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_lattice(lattice,\n",
        "                 n_sp,\n",
        "                 title=None,\n",
        "                 save=False,\n",
        "                 filename=None,\n",
        "                 hide_subset=False,\n",
        "                 subset_bounds=None,\n",
        "                 color_dict=None):\n",
        "  L = lattice.shape[0]\n",
        "  arr = lattice.copy()\n",
        "  if title is None:\n",
        "    title = ''\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111, projection='3d')\n",
        "  ax.set_title(title)\n",
        "  ax.set_xlim(0, L)\n",
        "  ax.set_ylim(0, L)\n",
        "  ax.set_zlim(0, L)\n",
        "  ax.set_xticks([0, L-1])\n",
        "  ax.set_yticks([0, L-1])\n",
        "  ax.set_zticks([0, L-1])\n",
        "  colors = np.zeros(arr.shape, dtype=object)\n",
        "\n",
        "  # Hide and/or bound subset\n",
        "  if subset_bounds:\n",
        "    (x_min, x_max, y_min, y_max, z_min, z_max) = subset_bounds\n",
        "    for i in range(x_min, x_max):\n",
        "        for j in range(y_min, y_max):\n",
        "            for k in range(z_min, z_max):\n",
        "                if hide_subset:\n",
        "                    arr[i, j, k] = 0\n",
        "    # Draw surfaces to cover tick lines inside the box\n",
        "    ax.plot_surface(np.array([[x_min, x_max], [x_min, x_max]]), np.array([[y_min, y_min], [y_max, y_max]]), np.array([[z_min, z_min], [z_min, z_min]]), color=(1, 1, 1, 0.1))\n",
        "    ax.plot_surface(np.array([[x_min, x_min], [x_max, x_max]]), np.array([[y_min, y_min], [y_max, y_max]]), np.array([[z_min, z_min], [z_max, z_max]]), color=(1, 1, 1, 0.5))\n",
        "    # Draw dotted boundary box\n",
        "    for corner in [(x_min, y_min, z_min), (x_min, y_min, z_max), (x_min, y_max, z_min), (x_min, y_max, z_max),\n",
        "                    (x_max, y_min, z_min), (x_max, y_min, z_max), (x_max, y_max, z_min), (x_max, y_max, z_max)]:\n",
        "        ax.plot([corner[0], corner[0]], [corner[1], corner[1]], [z_min, z_max], linestyle=':', color=(0, 0, 0, 0.5))\n",
        "        ax.plot([corner[0], corner[0]], [y_min, y_max], [corner[2], corner[2]], linestyle=':', color=(0, 0, 0, 0.5))\n",
        "        ax.plot([x_min, x_max], [corner[1], corner[1]], [corner[2], corner[2]], linestyle=':', color=(0, 0, 0, 0.5))\n",
        "  for i in range(1, n_sp):\n",
        "      colors[arr == i] = color_dict[i]\n",
        "  ax.voxels(arr,\n",
        "            facecolors=colors,\n",
        "            lightsource=mplcolors.LightSource(azdeg=135, altdeg=0))\n",
        "  if save:\n",
        "    plt.savefig(filename)\n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "\n",
        "\n",
        "def plot_g_ij(arr, title=None, save=False, filename=None):\n",
        "  if title is None:\n",
        "    title = ''\n",
        "  fig, ax = plt.subplots(1, 1)\n",
        "  arr = arr.copy()\n",
        "  ax.set_title(title)\n",
        "  ax.imshow(arr, cmap='gray')\n",
        "  absmax = np.max(np.abs(arr))\n",
        "  cbar = plt.colorbar(ax.imshow(arr,\n",
        "                                norm=mplcolors.TwoSlopeNorm(0, -absmax, absmax),\n",
        "                                cmap='coolwarm'),\n",
        "                      ax=ax,\n",
        "                      orientation='vertical',\n",
        "                      fraction=0.046,\n",
        "                      pad=0.04)\n",
        "  if save:\n",
        "    plt.savefig(filename)\n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "\n",
        "\n",
        "def plot_g_i(arr, title=None, save=False, filename=None):\n",
        "  if title is None:\n",
        "    title = ''\n",
        "  fig, ax = plt.subplots(1, 1)\n",
        "  arr = arr.copy()\n",
        "  ax.set_title(title)\n",
        "  ax.imshow([g_i], cmap='gray')\n",
        "  absmax = np.max(np.abs(arr))\n",
        "  cbar = plt.colorbar(ax.imshow([arr],\n",
        "                                norm=mplcolors.TwoSlopeNorm(0, -absmax, absmax),\n",
        "                                cmap='coolwarm'),\n",
        "                      ax=ax,\n",
        "                      orientation='vertical',\n",
        "                      fraction=0.046,\n",
        "                      pad=0.04)\n",
        "  if save:\n",
        "    plt.savefig(filename)\n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "\n",
        "\n",
        "def plot_memory_lattice(lattice,\n",
        "                        n_sp,\n",
        "                        title=None,\n",
        "                        save=False,\n",
        "                        filename=None,\n",
        "                        mem_filter=False):\n",
        "  L = lattice.shape[0]\n",
        "  arr = lattice.copy()\n",
        "  if title is None:\n",
        "    title = ''\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111, projection='3d')\n",
        "  ax.set_xlim(0, L)\n",
        "  ax.set_ylim(0, L)\n",
        "  ax.set_zlim(0, L)\n",
        "  ax.set_title(title)\n",
        "  ax.set_xticks([])\n",
        "  ax.set_xticklabels([])\n",
        "  ax.set_yticks([])\n",
        "  ax.set_yticklabels([])\n",
        "  ax.set_zticks([])\n",
        "  ax.set_zticklabels([])\n",
        "\n",
        "  discrete_cmap = plt.get_cmap('tab20', n_sp-1)\n",
        "  colors = np.zeros(arr.shape, dtype=np.dtype((np.float32, 4)))\n",
        "  for i in range(1, n_sp):\n",
        "    colors[arr == i] = discrete_cmap(i-1)\n",
        "  # Gray for inert species in inert species examples\n",
        "  colors[arr == n_sp] = (0.5, 0.5, 0.5, 1)\n",
        "\n",
        "  if mem_filter:\n",
        "        # Color species blue if it is in the mem_filter\n",
        "        for i in range(1, n_sp):\n",
        "            if i-1 in np.argwhere(MEMS[mem_filter] == 1).flatten():\n",
        "                colors[arr == i] = (0, 0, 1, 1)\n",
        "\n",
        "  l = mplcolors.LightSource(azdeg=135, altdeg=0)\n",
        "  ax.voxels(arr,\n",
        "            facecolors=colors,\n",
        "            lightsource=l)\n",
        "\n",
        "  # ax.voxels(arr,\n",
        "  #           facecolors=colors)\n",
        "\n",
        "  if save:\n",
        "    plt.savefig(f'{filename}')\n",
        "  else:\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Given a list of lattices, set each value >0 to 1 and plot a heat map in 3D\n",
        "def plot_heatmap(lattices, title=None, species=None, cmap = 'Blues', save=False, filename=None):\n",
        "    # Larger text\n",
        "    plt.rcParams.update({'font.size': 20})\n",
        "    if species:\n",
        "        lattices = [lattice == species for lattice in lattices]\n",
        "    else:\n",
        "        lattices = [lattice > 0 for lattice in lattices]\n",
        "    lattice = np.mean(lattices, axis=0)\n",
        "    fig, ax = plt.subplots()\n",
        "    if title:\n",
        "        ax.set_title(title)\n",
        "    heatmap_img = ax.imshow(np.rot90(lattice.sum(axis=2)), cmap=cmap, origin = 'lower')\n",
        "    # Add colorbar\n",
        "    cbar = plt.colorbar(heatmap_img)\n",
        "    cbar.set_label('Mean z-axis sum')\n",
        "    if save:\n",
        "        plt.savefig(f'{filename}.svg')\n",
        "    plt.show()\n",
        "    # Default text size\n",
        "    plt.rcParams.update({'font.size': 10})\n",
        "\n",
        "\n",
        "def plot_energies(energies, num_parallel_proposals, burn_in, num_samples):\n",
        "    if num_samples < 1:\n",
        "        raise ValueError(\"num_samples must be >= 1 to plot a broken axis.\")\n",
        "\n",
        "    e = np.asarray(energies, dtype=np.float64).ravel()\n",
        "    if e.shape[0] != num_samples + 1:\n",
        "        raise ValueError(\"Expected energies to have length num_samples + 1 (initial + samples).\")\n",
        "\n",
        "    sample_rate = (num_parallel_proposals - burn_in) // num_samples\n",
        "    if sample_rate <= 0:\n",
        "        raise ValueError(\"sample_rate <= 0. Need (num_parallel_proposals - burn_in) // num_samples >= 1.\")\n",
        "\n",
        "    x = np.empty(num_samples + 1, dtype=np.int64)\n",
        "    x[0] = 0\n",
        "    x[1:] = burn_in + np.arange(1, num_samples + 1, dtype=np.int64) * sample_rate\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(\n",
        "        1, 2, sharey=True,\n",
        "        gridspec_kw={\"width_ratios\": [1, 4], \"wspace\": 0.05}\n",
        "    )\n",
        "\n",
        "    # Left: single point only\n",
        "    ax1.plot([x[0]], [e[0]], marker=\"o\", linestyle=\"None\")\n",
        "\n",
        "    # Right: line plot over sampled region\n",
        "    ax2.plot(x[1:], e[1:])  # default is a line\n",
        "\n",
        "    left_pad = max(1, int(0.5 * sample_rate))\n",
        "    ax1.set_xlim(x[0] - left_pad, x[0] + left_pad)\n",
        "    ax1.set_xticks([x[0]])\n",
        "\n",
        "    right_pad = max(1, int(0.5 * sample_rate))\n",
        "    ax2.set_xlim(x[1] - right_pad, x[-1] + right_pad)\n",
        "\n",
        "    ax1.spines[\"right\"].set_visible(False)\n",
        "    ax2.spines[\"left\"].set_visible(False)\n",
        "    ax2.yaxis.tick_right()\n",
        "    ax2.tick_params(labelright=False)\n",
        "\n",
        "    d = 0.015\n",
        "    kwargs = dict(transform=ax1.transAxes, color=\"k\", clip_on=False)\n",
        "    ax1.plot((1 - d, 1 + d), (-d, +d), **kwargs)\n",
        "    ax1.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)\n",
        "\n",
        "    kwargs.update(transform=ax2.transAxes)\n",
        "    ax2.plot((-d, +d), (-d, +d), **kwargs)\n",
        "    ax2.plot((-d, +d), (1 - d, 1 + d), **kwargs)\n",
        "\n",
        "    fig.supxlabel(\"Parallel proposals run\")\n",
        "    ax1.set_ylabel(\"Energy\")\n",
        "\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "pU5JAbzVyinT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Helper functions"
      ],
      "metadata": {
        "id": "JF9e1Yxp4Bwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns discrete integer coordinates\n",
        "# for a discrete sphere centered at (a,b,c)\n",
        "# of radius r\n",
        "def sphere(a, b, c, r):\n",
        "    coords = []\n",
        "    for x in range(-r, r+1):\n",
        "        for y in range(-r, r+1):\n",
        "            for z in range(-r, r+1):\n",
        "                if (x+0.5)**2 + (y+0.5)**2 + (z+0.5)**2 <= r**2:\n",
        "                    coords.append((x+a, y+b, z+c))\n",
        "    return coords\n",
        "\n",
        "\n",
        "# numpy's shuffle only shuffles the first dim. of a multidim. array\n",
        "# This function will shuffle all of a 3D lattice\n",
        "def shuffle_lattice(lattice):\n",
        "  flattened_lattice = lattice.flatten()\n",
        "  np.random.shuffle(flattened_lattice)\n",
        "  return flattened_lattice.reshape(lattice.shape)\n",
        "\n",
        "\n",
        "# This function will replace 0s (solvent) of a lattice with other species until\n",
        "# the species counts match the target lattice's species counts\n",
        "# This function is slow and not well-made\n",
        "def match_counts(lattice, target_lattice):\n",
        "  species_counts = get_n_i(lattice, N_SP_AVO)\n",
        "  target_species_counts = get_n_i(target_lattice, N_SP_AVO)\n",
        "  for i in range(1, N_SP_AVO):\n",
        "    while species_counts[i] < target_species_counts[i]:\n",
        "      (x,y,z) = np.random.randint(0, LATTICE_LENGTH_AVO, 3)\n",
        "      if lattice[x,y,z] == 0:\n",
        "        lattice[x,y,z] = i\n",
        "        species_counts[i] += 1\n",
        "  return lattice\n"
      ],
      "metadata": {
        "id": "cIWlK4Mk4D_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Avocado"
      ],
      "metadata": {
        "id": "CdDfihX8ynFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Globals and helper functions"
      ],
      "metadata": {
        "id": "fCuEZGW0Y3Kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Four species:\n",
        "# 0: solvent\n",
        "# 1: avocado skin (outer)\n",
        "# 2: avocado flesh (middle)\n",
        "# 3: avocado pit (inner)\n",
        "N_SP_AVO = 4\n",
        "LATTICE_LENGTH_AVO = 24\n",
        "AVOCADO_CENTER_X = 12\n",
        "AVOCADO_CENTER_Y = 12\n",
        "AVOCADO_CENTER_Z = 12\n",
        "SKIN_RADIUS = 7\n",
        "FLESH_RADIUS = 5\n",
        "PIT_RADIUS = 3\n",
        "COLOR_DICT_AVO = {1: '0.2', 2: 'g', 3: 'y'}\n",
        "\n",
        "def avocado(x=AVOCADO_CENTER_X,\n",
        "            y=AVOCADO_CENTER_Y,\n",
        "            z=AVOCADO_CENTER_Z,\n",
        "            r1=SKIN_RADIUS,\n",
        "            r2=FLESH_RADIUS,\n",
        "            r3=PIT_RADIUS):\n",
        "    lattice = np.zeros((LATTICE_LENGTH_AVO,\n",
        "                        LATTICE_LENGTH_AVO,\n",
        "                        LATTICE_LENGTH_AVO),\n",
        "                       dtype = np.int32)\n",
        "    # skin\n",
        "    for pos in sphere(x, y, z, r1):\n",
        "        lattice[pos] = 1\n",
        "    # flesh\n",
        "    for pos in sphere(x, y, z, r2):\n",
        "        lattice[pos] = 2\n",
        "    # pit\n",
        "    for pos in sphere(x, y, z, r3):\n",
        "        lattice[pos] = 3\n",
        "    return lattice\n",
        "\n",
        "plot_lattice(avocado(), N_SP_AVO, title='Avocado', save=False, color_dict=COLOR_DICT_AVO)\n",
        "plot_lattice(avocado(), N_SP_AVO, title='Avocado', save=False, color_dict=COLOR_DICT_AVO, subset_bounds=(0, 24, 0, 12, 0, 24), hide_subset=True)"
      ],
      "metadata": {
        "id": "s9n95sRIzM1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training initialization"
      ],
      "metadata": {
        "id": "n4At_hoTY-kA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 100000\n",
        "parallel_proposals_per_epoch = LATTICE_LENGTH_AVO ** 4 * 4\n",
        "save_frequency = 10\n",
        "learning_rate = 5000 / LATTICE_LENGTH_AVO ** 3\n",
        "num_samples = 100\n",
        "\n",
        "epoch = 0\n",
        "g_ij = np.zeros((N_SP_AVO, N_SP_AVO))\n",
        "norm_sums = np.zeros_like(g_ij)\n",
        "\n",
        "folder_filename = f'avocado_{time.strftime(\"%Y%m%d-%H%M%S\")}'\n",
        "!mkdir $folder_filename\n",
        "with open(f'{folder_filename}/hyperparameters.txt', 'w') as f:\n",
        "  f.write(f'parallel_proposals_per_epoch: {parallel_proposals_per_epoch}\\n')\n",
        "  f.write(f'learning_rate: {learning_rate}\\n')"
      ],
      "metadata": {
        "id": "zHntqedVZCNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing function"
      ],
      "metadata": {
        "id": "vqrRAO7Wizz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(g_ij):\n",
        "  lattice = avocado()\n",
        "  lattice = shuffle_lattice(lattice)\n",
        "  lattice, _, _, energies = mcmc(lattice_batch = lattice,\n",
        "                                 num_parallel_proposals = parallel_proposals_per_epoch,\n",
        "                                 num_samples = num_samples,\n",
        "                                 burn_in = parallel_proposals_per_epoch//2,\n",
        "                                 num_species = N_SP_AVO,\n",
        "                                 g_ij_batch = g_ij,\n",
        "                                 canonical = True,\n",
        "                                 ranged = True,\n",
        "                                 periodic = True)\n",
        "  return lattice, energies"
      ],
      "metadata": {
        "id": "S3v6C48oi2j7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training epoch function"
      ],
      "metadata": {
        "id": "WAGQBrQ8mFwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_epoch(g_ij, learning_rate, adagrad=False, norm_sums=None):\n",
        "  dw = np.zeros_like(g_ij)\n",
        "\n",
        "  # Wake phase\n",
        "  n_ij = get_n_ij(avocado(), N_SP_AVO)\n",
        "  dw -= n_ij\n",
        "\n",
        "  # Sleep phase\n",
        "  lattice = avocado()\n",
        "  lattice = shuffle_lattice(lattice)\n",
        "  lattice, n_ij, _, energies = mcmc(lattice_batch = lattice,\n",
        "                                    num_parallel_proposals = parallel_proposals_per_epoch,\n",
        "                                    num_samples = num_samples,\n",
        "                                    burn_in = parallel_proposals_per_epoch//2,\n",
        "                                    num_species = N_SP_AVO,\n",
        "                                    g_ij_batch = g_ij,\n",
        "                                    canonical = True,\n",
        "                                    ranged = True,\n",
        "                                    periodic = True)\n",
        "  dw += n_ij\n",
        "\n",
        "  # Update weights\n",
        "  if adagrad:\n",
        "    norm_sums += dw ** 2\n",
        "    g_ij += learning_rate * dw / (1e-8 + np.sqrt(norm_sums))\n",
        "  else:\n",
        "    g_ij += learning_rate * dw\n",
        "  return g_ij, norm_sums, lattice, energies"
      ],
      "metadata": {
        "id": "idELfpMYmeZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YezcSD4xmIMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training"
      ],
      "metadata": {
        "id": "HLyL9v7hl06n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(max_epochs):\n",
        "  g_ij, norm_sums, lattice, energies = training_epoch(g_ij,\n",
        "                                                      learning_rate,\n",
        "                                                      adagrad=True,\n",
        "                                                      norm_sums=norm_sums)\n",
        "\n",
        "  if epoch % save_frequency == 0:\n",
        "    lattice, energies = test(g_ij)\n",
        "    plot_lattice(lattice, N_SP_AVO, title=f'Avocado, post epoch {epoch}', save=False, color_dict=COLOR_DICT_AVO)\n",
        "    plot_lattice(avocado(), N_SP_AVO, title=f'Avocado, post epoch {epoch}', save=False, color_dict=COLOR_DICT_AVO, subset_bounds=(0, 24, 0, 12, 0, 24), hide_subset=True)\n",
        "    plot_energies(energies,\n",
        "                  parallel_proposals_per_epoch,\n",
        "                  parallel_proposals_per_epoch//2,\n",
        "                  num_samples)\n",
        "    plt.imshow(g_ij, cmap='viridis')\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "  epoch = epoch + 1"
      ],
      "metadata": {
        "id": "tE2JIv7el3eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Paper-reported parameters and plotting\n",
        "Running this will overwrite trained $G_{ij}$"
      ],
      "metadata": {
        "id": "wM77zaaCCsQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_ij = np.load('avocado_g_ij.npy')\n",
        "plot_g_ij(g_ij, title='Avocado')"
      ],
      "metadata": {
        "id": "P9vsF7WL9XW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Unclamped testing"
      ],
      "metadata": {
        "id": "nz-vpFV8Ajtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lattice, energies = test(g_ij)\n",
        "\n",
        "plot_lattice(lattice, N_SP_AVO, title=f'Avocado', save=False, color_dict=COLOR_DICT_AVO)\n",
        "plot_lattice(lattice, N_SP_AVO, title=f'Avocado', save=False, color_dict=COLOR_DICT_AVO, subset_bounds=(0, 24, 0, 12, 0, 24), hide_subset=True)\n",
        "plot_energies(energies,\n",
        "              parallel_proposals_per_epoch,\n",
        "              parallel_proposals_per_epoch//2,\n",
        "              num_samples)\n",
        "plt.imshow(g_ij, cmap='viridis')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "stmwg9ebnPBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Radial density"
      ],
      "metadata": {
        "id": "NFF7KTPv_zfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_average_radial_density(lattices, save=False, filename=None):\n",
        "    # Larger text\n",
        "    plt.rcParams.update({'font.size': 22})\n",
        "    num_bins = 50\n",
        "    radial_densities = {0: [], 1: [], 2: [], 3: []}\n",
        "\n",
        "    # Process each lattice\n",
        "    for lattice in lattices:\n",
        "        lattice_shape = lattice.shape\n",
        "        indices = np.argwhere(lattice == 3)\n",
        "        if len(indices) == 0:\n",
        "            continue  # Skip if no '3' values found\n",
        "        center_of_mass = indices.mean(axis=0)\n",
        "        distances = np.linalg.norm(np.indices(lattice_shape).transpose(1, 2, 3, 0) - center_of_mass, axis=3)\n",
        "        max_distance = int(np.ceil(distances.max()))\n",
        "        bin_edges = np.linspace(0, max_distance, num_bins)\n",
        "        digitized = np.digitize(distances, bin_edges)\n",
        "        binned_values = {i: lattice[digitized == i] for i in range(1, len(bin_edges))}\n",
        "\n",
        "        for value in [0, 1, 2, 3]:\n",
        "            radial_density = [np.mean(bins == value) for bins in binned_values.values()]\n",
        "            radial_densities[value].append(radial_density)\n",
        "\n",
        "    # Averaging radial densities\n",
        "    averaged_radial_densities = {key: np.mean(np.vstack(values), axis=0) for key, values in radial_densities.items()}\n",
        "\n",
        "    # Plotting\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_title('Average radial density')\n",
        "    colors = ['gray', 'black', 'green', 'goldenrod']  # Colors for values 0, 1, 2, 3\n",
        "    for value in [0, 1, 2, 3]:\n",
        "        ax.plot(bin_edges[:-1], averaged_radial_densities[value], color=colors[value], label=f'Species {value}')\n",
        "\n",
        "    ax.set_xlabel('Distance from species 3 center')\n",
        "    ax.set_ylabel('Frequency')\n",
        "    ax.legend()\n",
        "    if save:\n",
        "        plt.savefig(f'{filename}.svg')\n",
        "    plt.show()\n",
        "    # Return text to default\n",
        "    plt.rcParams.update({'font.size': 10})\n",
        "\n"
      ],
      "metadata": {
        "id": "UtpxRuM7AMMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lattices = []\n",
        "for _ in range(100):\n",
        "  lattices.append(shuffle_lattice(avocado()))\n",
        "lattices = np.array(lattices, dtype=np.int32)\n",
        "lattices, _, _, energies_s = mcmc(lattice_batch = lattices,\n",
        "                                  num_parallel_proposals = parallel_proposals_per_epoch,\n",
        "                                  num_samples = num_samples,\n",
        "                                  burn_in = parallel_proposals_per_epoch//2,\n",
        "                                  num_species = N_SP_AVO,\n",
        "                                  g_ij_batch = g_ij,\n",
        "                                  canonical = True,\n",
        "                                  ranged = True)\n",
        "\n",
        "plot_average_radial_density(lattices, save=True, filename='average_radial_density.svg')"
      ],
      "metadata": {
        "id": "x04fOThkmiVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Clamped testing"
      ],
      "metadata": {
        "id": "DPXKGGdgd5A0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Surface"
      ],
      "metadata": {
        "id": "ONkn5ChEfC9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lattice = np.zeros((LATTICE_LENGTH_AVO, LATTICE_LENGTH_AVO, LATTICE_LENGTH_AVO))\n",
        "lattice[0, :, :] = avocado()[12, :, :]\n",
        "\n",
        "plot_lattice(lattice, N_SP_AVO, title='Surface clamp', color_dict=COLOR_DICT_AVO)\n",
        "\n",
        "free_pos = np.ones_like(lattice)\n",
        "free_pos[lattice != 0] = 0\n",
        "\n",
        "lattice = match_counts(lattice, avocado())\n",
        "\n",
        "plot_lattice(lattice, N_SP_AVO, title='Surface clamp initital', color_dict=COLOR_DICT_AVO)\n",
        "\n",
        "lattice, _, _, _ = mcmc(lattice_batch = lattice,\n",
        "                        num_parallel_proposals = parallel_proposals_per_epoch,\n",
        "                        num_samples = num_samples,\n",
        "                        burn_in = parallel_proposals_per_epoch//2,\n",
        "                        num_species = N_SP_AVO,\n",
        "                        g_ij_batch = g_ij,\n",
        "                        free_pos_batch = free_pos,\n",
        "                        canonical = True,\n",
        "                        ranged = True)\n",
        "\n",
        "plot_lattice(lattice, N_SP_AVO, title='Surface clamp final', color_dict=COLOR_DICT_AVO)"
      ],
      "metadata": {
        "id": "W6-higjofGrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lattice = np.zeros((LATTICE_LENGTH_AVO, LATTICE_LENGTH_AVO, LATTICE_LENGTH_AVO))\n",
        "lattice[0, :, :] = avocado()[12, :, :]\n",
        "\n",
        "free_pos = np.ones_like(lattice)\n",
        "free_pos[lattice != 0] = 0\n",
        "free_pos_batch = [free_pos] * 100\n",
        "\n",
        "lattices = []\n",
        "for _ in range(100):\n",
        "  lattices.append(match_counts(lattice.copy(), avocado()))\n",
        "\n",
        "lattices, _, _, _ = mcmc(lattice_batch = lattices,\n",
        "                         num_parallel_proposals = parallel_proposals_per_epoch,\n",
        "                         num_samples = num_samples,\n",
        "                         burn_in = parallel_proposals_per_epoch//2,\n",
        "                         num_species = N_SP_AVO,\n",
        "                         g_ij_batch = g_ij,\n",
        "                         free_pos_batch = free_pos_batch,\n",
        "                         canonical = True,\n",
        "                         ranged = True,\n",
        "                         save_lattices = True)\n",
        "\n",
        "# Flattens lattices list returned by mcmc, which is a list of list of lattices,\n",
        "# into a list of lattices.\n",
        "lattices = [item for sublist in lattices for item in sublist]\n",
        "\n",
        "plot_heatmap(lattices, title='Aggregate Heatmap\\n 10,000 samples', cmap = 'hot')"
      ],
      "metadata": {
        "id": "qyTGSi9yGHdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5nN1YKddHEuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Polymer clamp"
      ],
      "metadata": {
        "id": "Ux6Z90P2zf4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lattice = np.zeros((LATTICE_LENGTH_AVO, LATTICE_LENGTH_AVO, LATTICE_LENGTH_AVO))\n",
        "lattice[:, 12, 12] = avocado()[:, 12, 12]\n",
        "\n",
        "plot_lattice(lattice, N_SP_AVO, title='Polymer clamp', color_dict=COLOR_DICT_AVO)\n",
        "\n",
        "free_pos = np.ones_like(lattice)\n",
        "free_pos[lattice != 0] = 0\n",
        "\n",
        "lattice = match_counts(lattice, avocado())\n",
        "\n",
        "plot_lattice(lattice, N_SP_AVO, title='Polymer clamp initital', color_dict=COLOR_DICT_AVO)\n",
        "\n",
        "lattice, _, _, _ = mcmc(lattice_batch = lattice,\n",
        "                        num_parallel_proposals = parallel_proposals_per_epoch,\n",
        "                        num_samples = num_samples,\n",
        "                        burn_in = parallel_proposals_per_epoch//2,\n",
        "                        num_species = N_SP_AVO,\n",
        "                        g_ij_batch = g_ij,\n",
        "                        free_pos_batch = free_pos,\n",
        "                        canonical = True,\n",
        "                        ranged = True)\n",
        "\n",
        "plot_lattice(lattice, N_SP_AVO, title='Polymer clamp final', color_dict=COLOR_DICT_AVO)"
      ],
      "metadata": {
        "id": "i40pIucTzlrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lattice = np.zeros((LATTICE_LENGTH_AVO, LATTICE_LENGTH_AVO, LATTICE_LENGTH_AVO))\n",
        "lattice[:, 12, 12] = avocado()[:, 12, 12]\n",
        "\n",
        "free_pos = np.ones_like(lattice)\n",
        "free_pos[lattice != 0] = 0\n",
        "free_pos_s = [free_pos] * 100\n",
        "\n",
        "lattices = []\n",
        "for _ in range(100):\n",
        "  lattices.append(match_counts(lattice.copy(), avocado()))\n",
        "\n",
        "lattices, _, _, _ = mcmc(lattice_batch = lattices,\n",
        "                        num_parallel_proposals = parallel_proposals_per_epoch,\n",
        "                        num_samples = num_samples,\n",
        "                        burn_in = parallel_proposals_per_epoch//2,\n",
        "                        num_species = N_SP_AVO,\n",
        "                        g_ij_batch = g_ij,\n",
        "                        free_pos_batch = free_pos_s,\n",
        "                        canonical = True,\n",
        "                        ranged = True,\n",
        "                        save_lattices = True)\n",
        "\n",
        "# Flattens lattices list returned by mcmc, which is a list of list of lattices,\n",
        "# into a list of lattices.\n",
        "lattices = [item for sublist in lattices for item in sublist]\n",
        "\n",
        "plot_heatmap(lattices, title='Aggregate Heatmap\\n 10,000 samples', cmap = 'hot')"
      ],
      "metadata": {
        "id": "8NeCR05H3fcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Ordered vs. unordered surface"
      ],
      "metadata": {
        "id": "utZy_Q1-6Jrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lattice = np.zeros((LATTICE_LENGTH_AVO, LATTICE_LENGTH_AVO, LATTICE_LENGTH_AVO))\n",
        "lattice[0, :, :] = avocado(r1=9, r2=7, r3=4)[12, :, :]\n",
        "\n",
        "random_surface = np.zeros((LATTICE_LENGTH_AVO, LATTICE_LENGTH_AVO))\n",
        "for pos in sphere(12, 12, 12, 9):\n",
        "  if pos[0] == 12:\n",
        "    random_surface[pos[1], pos[2]] = np.random.randint(1, N_SP_AVO)\n",
        "lattice[-1, :, :] = random_surface\n",
        "\n",
        "plot_lattice(lattice, N_SP_AVO, title='Ordered vs. unordered surface clamp', color_dict=COLOR_DICT_AVO)\n",
        "\n",
        "free_pos = np.ones_like(lattice)\n",
        "free_pos[lattice != 0] = 0\n",
        "\n",
        "lattice = match_counts(lattice, avocado())\n",
        "\n",
        "plot_lattice(lattice, N_SP_AVO, title='Ordered vs. unordered surface clamp initital', color_dict=COLOR_DICT_AVO)\n",
        "\n",
        "lattice, _, _, _ = mcmc(lattice_batch = lattice,\n",
        "                        num_parallel_proposals =parallel_proposals_per_epoch,\n",
        "                        num_samples = num_samples,\n",
        "                        burn_in = parallel_proposals_per_epoch//2,\n",
        "                        num_species = N_SP_AVO,\n",
        "                        g_ij_batch = g_ij,\n",
        "                        free_pos_batch = free_pos,\n",
        "                        canonical = True,\n",
        "                        ranged = True)\n",
        "\n",
        "plot_lattice(lattice, N_SP_AVO, title='Ordered vs. unordered surface clamp final', color_dict=COLOR_DICT_AVO)"
      ],
      "metadata": {
        "id": "A6INOHF46sy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lattice = np.zeros((LATTICE_LENGTH_AVO, LATTICE_LENGTH_AVO, LATTICE_LENGTH_AVO))\n",
        "lattice[0, :, :] = avocado(r1=9, r2=7, r3=4)[12, :, :]\n",
        "\n",
        "random_surface = np.zeros((LATTICE_LENGTH_AVO, LATTICE_LENGTH_AVO))\n",
        "for pos in sphere(12, 12, 12, 9):\n",
        "  if pos[0] == 12:\n",
        "    random_surface[pos[1], pos[2]] = np.random.randint(1, N_SP_AVO)\n",
        "lattice[-1, :, :] = random_surface\n",
        "\n",
        "free_pos = np.ones_like(lattice)\n",
        "free_pos[lattice != 0] = 0\n",
        "free_pos_s = [free_pos] * 100\n",
        "\n",
        "lattices = []\n",
        "for _ in range(100):\n",
        "  lattices.append(match_counts(lattice.copy(), avocado()))\n",
        "\n",
        "lattices, _, _, _ = mcmc(lattice_batch = lattices,\n",
        "                        num_parallel_proposals =parallel_proposals_per_epoch,\n",
        "                        num_samples = num_samples,\n",
        "                        burn_in = parallel_proposals_per_epoch//2,\n",
        "                        num_species = N_SP_AVO,\n",
        "                        g_ij_batch = g_ij,\n",
        "                        free_pos_batch = free_pos_s,\n",
        "                        canonical = True,\n",
        "                        ranged = True,\n",
        "                        save_lattices = True)\n",
        "\n",
        "# Flattens lattices list returned by mcmc, which is a list of list of lattices,\n",
        "# into a list of lattices.\n",
        "lattices = [item for sublist in lattices for item in sublist]\n",
        "\n",
        "plot_heatmap(lattices, title='Aggregate Heatmap\\n 10,000 samples', cmap = 'hot')"
      ],
      "metadata": {
        "id": "Qu3jPvxg_m5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hopfield condensates: surface-conditioned associative recall"
      ],
      "metadata": {
        "id": "3jGGNvVUGwec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Globals and helper functions"
      ],
      "metadata": {
        "id": "8RAHBtNSIKn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_MEMS = 2\n",
        "MEM_LENGTH = 16\n",
        "MEMS = np.array([np.array([0, 1, 0, 1,\n",
        "                           1, 0, 0, 1,\n",
        "                           1, 0, 0, 0,\n",
        "                           0, 1, 1, 1]),\n",
        "                 np.array([1, 0, 0, 1,\n",
        "                           0, 1, 0, 1,\n",
        "                           0, 1, 1, 1,\n",
        "                           0, 0, 0, 1])])\n",
        "\n",
        "# 0: solvent\n",
        "# 1-16: \"memory\" species\n",
        "N_SP_HOPFIELD = 1 + MEM_LENGTH\n",
        "LATTICE_LENGTH_HOPFIELD = 12\n",
        "\n",
        "def sphere_with_memory_composition(lattice,\n",
        "                                   memory,\n",
        "                                   a,\n",
        "                                   b,\n",
        "                                   c,\n",
        "                                   r):\n",
        "  for coord in sphere(a, b, c, r):\n",
        "    # This check allows placement of a semi-sphere against the wall (see cell below)\n",
        "    if coord[0] >= 0:\n",
        "      lattice[coord] = np.random.choice(np.argwhere(memory == 1).flatten()) + 1\n",
        "  return lattice\n",
        "\n",
        "def surface_with_memory_composition(lattice,\n",
        "                                    memory,\n",
        "                                    a,\n",
        "                                    b,\n",
        "                                    c,\n",
        "                                    r):\n",
        "  for coord in sphere(a, b, c, r):\n",
        "    if coord[0] == 0:\n",
        "      lattice[coord] = np.random.choice(np.argwhere(memory == 1).flatten()) + 1\n",
        "  return lattice"
      ],
      "metadata": {
        "id": "wIdrqhPeINTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lattice = sphere_with_memory_composition(np.zeros((LATTICE_LENGTH_HOPFIELD,\n",
        "                                                   LATTICE_LENGTH_HOPFIELD,\n",
        "                                                   LATTICE_LENGTH_HOPFIELD),\n",
        "                                                  dtype=np.int32),\n",
        "                                         MEMS[0],\n",
        "                                         0,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2-1)\n",
        "plot_memory_lattice(lattice,\n",
        "                    N_SP_HOPFIELD,\n",
        "                    title='Memory 0')\n",
        "lattice = sphere_with_memory_composition(np.zeros((LATTICE_LENGTH_HOPFIELD,\n",
        "                                                   LATTICE_LENGTH_HOPFIELD,\n",
        "                                                   LATTICE_LENGTH_HOPFIELD),\n",
        "                                                  dtype=np.int32),\n",
        "                                         MEMS[1],\n",
        "                                         0,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2-1)\n",
        "plot_memory_lattice(lattice,\n",
        "                    N_SP_HOPFIELD,\n",
        "                    title='Memory 1')\n",
        "\n",
        "lattice = surface_with_memory_composition(np.zeros((LATTICE_LENGTH_HOPFIELD,\n",
        "                                                   LATTICE_LENGTH_HOPFIELD,\n",
        "                                                   LATTICE_LENGTH_HOPFIELD),\n",
        "                                                  dtype=np.int32),\n",
        "                                         MEMS[0],\n",
        "                                         0,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2-1)\n",
        "plot_memory_lattice(lattice,\n",
        "                    N_SP_HOPFIELD,\n",
        "                    title='Memory 0')\n",
        "\n",
        "lattice = surface_with_memory_composition(np.zeros((LATTICE_LENGTH_HOPFIELD,\n",
        "                                                   LATTICE_LENGTH_HOPFIELD,\n",
        "                                                   LATTICE_LENGTH_HOPFIELD),\n",
        "                                                  dtype=np.int32),\n",
        "                                         MEMS[1],\n",
        "                                         0,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2-1)\n",
        "plot_memory_lattice(lattice,\n",
        "                    N_SP_HOPFIELD,\n",
        "                    title='Memory 1')"
      ],
      "metadata": {
        "id": "ri2R9xjCYQPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training initialization"
      ],
      "metadata": {
        "id": "tywe2VK6bBA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 100000\n",
        "parallel_proposals_per_epoch = LATTICE_LENGTH_HOPFIELD ** 4 * 40\n",
        "save_frequency = 10\n",
        "learning_rate = 1 / LATTICE_LENGTH_HOPFIELD ** 3\n",
        "num_samples = 100\n",
        "\n",
        "epoch = 0\n",
        "g_ij = np.zeros((N_SP_HOPFIELD, N_SP_HOPFIELD))\n",
        "g_i = np.zeros(N_SP_HOPFIELD)\n",
        "for i in range(1, N_SP_HOPFIELD):\n",
        "  g_i[i] = 8\n",
        "\n",
        "norm_sums_ij = np.zeros_like(g_ij)\n",
        "norm_sums_i = np.zeros_like(g_i)\n",
        "\n",
        "folder_filename = f'hopfield_{time.strftime(\"%Y%m%d-%H%M%S\")}'\n",
        "!mkdir $folder_filename\n",
        "with open(f'{folder_filename}/hyperparameters.txt', 'w') as f:\n",
        "  f.write(f'parallel_proposals_per_epoch: {parallel_proposals_per_epoch}\\n')\n",
        "  f.write(f'learning_rate: {learning_rate}\\n')"
      ],
      "metadata": {
        "id": "jTAmOVJ5bHnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing function"
      ],
      "metadata": {
        "id": "aMgpN7u6jSVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_hopfield(g_ij, g_i):\n",
        "  lattices = []\n",
        "  surface_counts_s = []\n",
        "  free_pos_batch = []\n",
        "  for mem in MEMS:\n",
        "    lattice = surface_with_memory_composition(np.zeros((LATTICE_LENGTH_HOPFIELD,\n",
        "                                                        LATTICE_LENGTH_HOPFIELD,\n",
        "                                                        LATTICE_LENGTH_HOPFIELD),\n",
        "                                                       dtype=np.int32),\n",
        "                                              mem,\n",
        "                                              0,\n",
        "                                              LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                              LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                              LATTICE_LENGTH_HOPFIELD//2-1)\n",
        "    lattices.append(lattice)\n",
        "\n",
        "    free_positions = np.ones_like(lattice)\n",
        "    free_positions[np.where(lattice)] = 0\n",
        "    free_pos_batch.append(free_positions)\n",
        "\n",
        "    surface_counts = get_n_i(lattice, N_SP_HOPFIELD)\n",
        "    surface_counts_s.append(surface_counts)\n",
        "\n",
        "  lattices, _, counts_avgs_s, energies_s = mcmc(lattice_batch = lattices,\n",
        "                                                num_parallel_proposals = parallel_proposals_per_epoch,\n",
        "                                                num_samples = num_samples,\n",
        "                                                burn_in = parallel_proposals_per_epoch//2,\n",
        "                                                num_species = N_SP_HOPFIELD,\n",
        "                                                g_ij_batch = g_ij,\n",
        "                                                g_i_batch = g_i,\n",
        "                                                free_pos_batch = free_pos_batch)\n",
        "\n",
        "  for i in range(len(lattices)):\n",
        "    plot_memory_lattice(lattices[i],\n",
        "                        N_SP_HOPFIELD,\n",
        "                        title=f'Memory {i}')\n",
        "    plt.imshow([MEMS[i]])\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "    nonsurface_counts_avgs = counts_avgs_s[i] - surface_counts_s[i]\n",
        "    plt.imshow([nonsurface_counts_avgs[1:]])\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "    plot_energies(energies_s[i],\n",
        "                  parallel_proposals_per_epoch,\n",
        "                  parallel_proposals_per_epoch//2,\n",
        "                  num_samples)\n"
      ],
      "metadata": {
        "id": "vwQLVo9vlAZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training epoch function"
      ],
      "metadata": {
        "id": "6Ofp-wFKgyYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_epoch(g_ij, g_i, learning_rate, adagrad=False, norm_sums_ij=None, norm_sums_i=None):\n",
        "  dw = np.zeros_like(g_ij)\n",
        "  db = np.zeros_like(g_i)\n",
        "\n",
        "  # Wake phase\n",
        "  for mem in MEMS:\n",
        "    lattice = sphere_with_memory_composition(np.zeros((LATTICE_LENGTH_HOPFIELD,\n",
        "                                                       LATTICE_LENGTH_HOPFIELD,\n",
        "                                                       LATTICE_LENGTH_HOPFIELD),\n",
        "                                                       dtype=np.int32),\n",
        "                                             mem,\n",
        "                                             0,\n",
        "                                             LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                             LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                             LATTICE_LENGTH_HOPFIELD//2-1)\n",
        "    n_ij = get_n_ij(lattice, N_SP_HOPFIELD)\n",
        "    n_i = get_n_i(lattice, N_SP_HOPFIELD)\n",
        "    dw -= n_ij\n",
        "    db -= n_i\n",
        "\n",
        "  # Sleep phase\n",
        "  lattices = []\n",
        "  free_pos_batch = []\n",
        "\n",
        "  for mem in MEMS:\n",
        "    lattice = surface_with_memory_composition(np.zeros((LATTICE_LENGTH_HOPFIELD,\n",
        "                                                        LATTICE_LENGTH_HOPFIELD,\n",
        "                                                        LATTICE_LENGTH_HOPFIELD),\n",
        "                                                        dtype=np.int32),\n",
        "                                              MEMS[1],\n",
        "                                              0,\n",
        "                                              LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                              LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                              LATTICE_LENGTH_HOPFIELD//2-1)\n",
        "    lattices.append(lattice)\n",
        "\n",
        "    free_positions = np.ones_like(lattice)\n",
        "    free_positions[np.where(lattice)] = 0\n",
        "    free_pos_batch.append(free_positions)\n",
        "\n",
        "  lattices, n_ij_avgs_s, n_i_avgs_s, energies_s = mcmc(lattice_batch = lattices,\n",
        "                                                       num_parallel_proposals = parallel_proposals_per_epoch,\n",
        "                                                       num_samples = num_samples,\n",
        "                                                       burn_in = parallel_proposals_per_epoch//2,\n",
        "                                                       num_species = N_SP_HOPFIELD,\n",
        "                                                       g_ij_batch = g_ij,\n",
        "                                                       g_i_batch = g_i,\n",
        "                                                       free_pos_batch = free_pos_batch)\n",
        "\n",
        "  for i in range(len(lattices)):\n",
        "    dw += n_ij_avgs_s[i]\n",
        "    db += n_i_avgs_s[i]\n",
        "\n",
        "  if adagrad:\n",
        "    norm_sums_ij += dw ** 2\n",
        "    norm_sums_i += db ** 2\n",
        "    g_ij += learning_rate * dw / np.sqrt(norm_sums_ij + 1e-8)\n",
        "    g_i += learning_rate * db / np.sqrt(norm_sums_i + 1e-8)\n",
        "  else:\n",
        "    g_ij += learning_rate * dw\n",
        "    g_i += learning_rate * db\n",
        "  return g_ij, g_i, norm_sums_ij, norm_sums_i"
      ],
      "metadata": {
        "id": "bhm9Y36og2jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training"
      ],
      "metadata": {
        "id": "L7QS2LSeq4nX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(max_epochs):\n",
        "  g_ij, _, _, _ = training_epoch(g_ij,\n",
        "                                 g_i,\n",
        "                                 learning_rate)\n",
        "\n",
        "  if epoch % save_frequency == 0:\n",
        "    clear_output(wait=True)\n",
        "    np.save(f'{folder_filename}/g_ij_{epoch}', g_ij)\n",
        "    np.save(f'{folder_filename}/g_i_{epoch}', g_i)\n",
        "    test_hopfield(g_ij, g_i)\n",
        "    plt.imshow(g_ij)\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "    plt.imshow([g_i])\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "  epoch = epoch + 1"
      ],
      "metadata": {
        "id": "dSwY-VP6q674"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Paper-reported parameters and plotting\n",
        "Running this will overwrite trained $G_{ij}$, $G_i$"
      ],
      "metadata": {
        "id": "WGxncIw7DCgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_ij = np.load('hopfield_g_ij.npy')\n",
        "g_i = np.load('hopfield_g_i.npy')\n",
        "plot_g_ij(g_ij)\n",
        "plot_g_i(g_i)"
      ],
      "metadata": {
        "id": "xSJZYJxdGVrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Surface recall"
      ],
      "metadata": {
        "id": "bWxZNFJ_up6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_hopfield(g_ij, g_i)"
      ],
      "metadata": {
        "id": "bsKBkuhqIKs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Partial memory recall"
      ],
      "metadata": {
        "id": "b526PVZMwjf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Partial memory 0"
      ],
      "metadata": {
        "id": "MGJRxCxZaQfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "partial_memory = np.array([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0])\n",
        "\n",
        "lattice = surface_with_memory_composition(np.zeros((LATTICE_LENGTH_HOPFIELD,\n",
        "                                                   LATTICE_LENGTH_HOPFIELD,\n",
        "                                                   LATTICE_LENGTH_HOPFIELD),\n",
        "                                                  dtype = np.int32),\n",
        "                                         partial_memory,\n",
        "                                         0,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2-1)\n",
        "\n",
        "surface_counts = get_n_i(lattice, N_SP_HOPFIELD)\n",
        "\n",
        "plot_memory_lattice(lattice,\n",
        "                    N_SP_HOPFIELD,\n",
        "                    title='Partial memory surface')\n",
        "\n",
        "free_positions = np.ones_like(lattice)\n",
        "free_positions[np.where(lattice)] = 0\n",
        "\n",
        "lattice, _, counts_avg, energies = mcmc(lattice_batch = lattice,\n",
        "                                         num_parallel_proposals = parallel_proposals_per_epoch,\n",
        "                                         num_samples = num_samples,\n",
        "                                         burn_in = parallel_proposals_per_epoch//2,\n",
        "                                         num_species = N_SP_HOPFIELD,\n",
        "                                         g_ij_batch = g_ij,\n",
        "                                         g_i_batch = g_i,\n",
        "                                         free_pos_batch = free_positions)\n",
        "\n",
        "plot_memory_lattice(lattice,\n",
        "                        N_SP_HOPFIELD,\n",
        "                        title='Partial memory recall')\n",
        "plt.imshow([MEMS[0]])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "nonsurface_counts_avg = counts_avg - surface_counts\n",
        "plt.imshow([nonsurface_counts_avg[1:]])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plot_energies(energies,\n",
        "              parallel_proposals_per_epoch,\n",
        "              parallel_proposals_per_epoch//2,\n",
        "              num_samples)"
      ],
      "metadata": {
        "id": "3X_YSUFlaVyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Partial memory 1"
      ],
      "metadata": {
        "id": "xnsEFl4uaBd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "partial_memory = np.array([0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "\n",
        "lattice = surface_with_memory_composition(np.zeros((LATTICE_LENGTH_HOPFIELD,\n",
        "                                                   LATTICE_LENGTH_HOPFIELD,\n",
        "                                                   LATTICE_LENGTH_HOPFIELD),\n",
        "                                                  dtype=np.int32),\n",
        "                                         partial_memory,\n",
        "                                         0,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2,\n",
        "                                         LATTICE_LENGTH_HOPFIELD//2-1)\n",
        "\n",
        "surface_counts = get_n_i(lattice, N_SP_HOPFIELD)\n",
        "\n",
        "plot_memory_lattice(lattice,\n",
        "                    N_SP_HOPFIELD,\n",
        "                    title='Partial memory surface')\n",
        "\n",
        "free_positions = np.ones_like(lattice)\n",
        "free_positions[np.where(lattice)] = 0\n",
        "\n",
        "lattice, _, counts_avg, energies = mcmc(lattice_batch = lattice,\n",
        "                                         num_parallel_proposals =parallel_proposals_per_epoch,\n",
        "                                         num_samples = num_samples,\n",
        "                                         burn_in = parallel_proposals_per_epoch//2,\n",
        "                                         num_species = N_SP_HOPFIELD,\n",
        "                                         g_ij_batch = g_ij,\n",
        "                                         g_i_batch = g_i,\n",
        "                                         free_pos_batch = free_positions)\n",
        "\n",
        "plot_memory_lattice(lattice,\n",
        "                        N_SP_HOPFIELD,\n",
        "                        title=f'Partial memory recall')\n",
        "plt.imshow([MEMS[1]])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "nonsurface_counts_avg = counts_avg - surface_counts\n",
        "plt.imshow([nonsurface_counts_avg[1:]])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plot_energies(energies,\n",
        "              parallel_proposals_per_epoch,\n",
        "              parallel_proposals_per_epoch//2,\n",
        "              num_samples)"
      ],
      "metadata": {
        "id": "atta87emwoAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Partial polymer recall"
      ],
      "metadata": {
        "id": "a6uSpt_R-Jj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "polymer_positions_in_plane = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                                       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
        "                                       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                                       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
        "                                       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "                                       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
        "                                       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                                       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
        "                                       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "                                       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
        "                                       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                                       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
        "\n",
        "def string_lattice(mem):\n",
        "  lattice = np.zeros((LATTICE_LENGTH_HOPFIELD,\n",
        "                      LATTICE_LENGTH_HOPFIELD,\n",
        "                      LATTICE_LENGTH_HOPFIELD),\n",
        "                     dtype=np.int32)\n",
        "  for j in range(LATTICE_LENGTH_HOPFIELD):\n",
        "    for k in range(LATTICE_LENGTH_HOPFIELD):\n",
        "      if polymer_positions_in_plane[j, k] == 1:\n",
        "        lattice[j, k, LATTICE_LENGTH_HOPFIELD//2] = np.random.choice(np.argwhere(mem==1).flatten())+1\n",
        "  return lattice"
      ],
      "metadata": {
        "id": "zBCUNBZN-vsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lattice = string_lattice(partial_memory)\n",
        "\n",
        "free_positions = np.ones_like(lattice)\n",
        "free_positions[np.where(lattice)] = 0\n",
        "\n",
        "surface_counts = get_n_i(lattice, N_SP_HOPFIELD)\n",
        "\n",
        "plot_memory_lattice(lattice,\n",
        "                    N_SP_HOPFIELD,\n",
        "                    title='Partial polymer clamp')\n",
        "\n",
        "lattice, _, counts_avg, energies = mcmc(lattice_batch = lattice,\n",
        "                                         num_parallel_proposals =parallel_proposals_per_epoch,\n",
        "                                         num_samples = num_samples,\n",
        "                                         burn_in = parallel_proposals_per_epoch//2,\n",
        "                                         num_species = N_SP_HOPFIELD,\n",
        "                                         g_ij_batch = g_ij,\n",
        "                                         g_i_batch = g_i,\n",
        "                                         free_pos_batch = free_positions)\n",
        "\n",
        "plot_memory_lattice(lattice,\n",
        "                        N_SP_HOPFIELD,\n",
        "                        title=f'Partial polymer recall')\n",
        "plt.imshow([MEMS[1]])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "nonsurface_counts_avg = counts_avg - surface_counts\n",
        "plt.imshow([nonsurface_counts_avg[1:]])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plot_energies(energies,\n",
        "              parallel_proposals_per_epoch,\n",
        "              parallel_proposals_per_epoch//2,\n",
        "              num_samples)"
      ],
      "metadata": {
        "id": "VUeYIw5SBQCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###"
      ],
      "metadata": {
        "id": "BRYIczwj32Q-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Surface pattern recognition"
      ],
      "metadata": {
        "id": "ZMeQpKHv4h7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Globals and helper functions"
      ],
      "metadata": {
        "id": "XZL9_p9z6AUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LATTICE_LENGTH_SPR = 8\n",
        "\n",
        "N_DATA = 2\n",
        "N_CLASS = 2\n",
        "N_HIDDEN = 4\n",
        "N_SP_SPR = 1 + N_DATA + N_CLASS + N_HIDDEN\n",
        "\n",
        "COLOR_DICT_SPR = {1: 'k',\n",
        "                  2: 'gray',\n",
        "                  3: 'r',\n",
        "                  4: 'b',\n",
        "                  5: 'lawngreen',\n",
        "                  6: 'yellow',\n",
        "                  7: 'magenta',\n",
        "                  8: 'cyan'}\n",
        "\n",
        "def checkerboard(length):\n",
        "    arr = np.ones((length, length), dtype=np.int32)\n",
        "    arr[1::2, ::2] = 2\n",
        "    arr[::2, 1::2] = 2\n",
        "    return arr\n",
        "\n",
        "\n",
        "def halfnhalf(length):\n",
        "    arr = np.ones((length, length), dtype=np.int32)\n",
        "    arr[length//2:, :] = 2\n",
        "    return arr\n",
        "\n",
        "\n",
        "def shuffled_hidden(length):\n",
        "    arr = np.zeros((length, length), dtype=np.int32)\n",
        "    arr[:length//2, :length//2] = 5\n",
        "    arr[length//2:, :length//2] = 6\n",
        "    arr[:length//2, length//2:] = 7\n",
        "    arr[length//2:, length//2:] = 8\n",
        "    arr = arr.flatten()\n",
        "    np.random.shuffle(arr)\n",
        "    arr = arr.reshape((length, length))\n",
        "    return arr\n",
        "\n",
        "\n",
        "def training_distribution():\n",
        "    lattice = np.zeros((LATTICE_LENGTH_SPR,\n",
        "                        LATTICE_LENGTH_SPR,\n",
        "                        LATTICE_LENGTH_SPR), dtype=np.int32)\n",
        "    # Set the initial state\n",
        "    lattice[0] = checkerboard(LATTICE_LENGTH_SPR)\n",
        "    lattice[-1] = halfnhalf(LATTICE_LENGTH_SPR)\n",
        "    lattice[2] = 3\n",
        "    lattice[-3] = 4\n",
        "    lattice[1] = shuffled_hidden(LATTICE_LENGTH_SPR)\n",
        "    lattice[-2] = shuffled_hidden(LATTICE_LENGTH_SPR)\n",
        "    return lattice\n",
        "\n",
        "def test_lattice():\n",
        "  lattice = np.zeros((LATTICE_LENGTH_SPR,\n",
        "                      LATTICE_LENGTH_SPR,\n",
        "                      LATTICE_LENGTH_SPR),\n",
        "                     dtype=np.int32)\n",
        "  lattice[0] = checkerboard(LATTICE_LENGTH_SPR)\n",
        "  lattice[-1] = halfnhalf(LATTICE_LENGTH_SPR)\n",
        "  lattice[2] = 3\n",
        "  lattice[-3] = 4\n",
        "  lattice[1] = shuffled_hidden(LATTICE_LENGTH_SPR)\n",
        "  lattice[-2] = shuffled_hidden(LATTICE_LENGTH_SPR)\n",
        "  innards = lattice.copy()[1:-1, :, :]\n",
        "  # shuffle innards\n",
        "  innards = innards.flatten()\n",
        "  np.random.shuffle(innards)\n",
        "  innards = innards.reshape((LATTICE_LENGTH_SPR-2, LATTICE_LENGTH_SPR, LATTICE_LENGTH_SPR))\n",
        "  lattice[1:-1, :, :] = innards\n",
        "  return lattice"
      ],
      "metadata": {
        "id": "ZSk_FORY4nT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_lattice(training_distribution(), N_SP_SPR, color_dict=COLOR_DICT_SPR)\n",
        "\n",
        "plot_lattice(test_lattice(), N_SP_SPR, color_dict=COLOR_DICT_SPR)"
      ],
      "metadata": {
        "id": "Voa11d6c9G5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training initialization"
      ],
      "metadata": {
        "id": "OakHgMgwCP0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 100000\n",
        "parallel_proposals_per_epoch = LATTICE_LENGTH_SPR ** 4 * 100\n",
        "save_frequency = 10\n",
        "learning_rate = 50 / LATTICE_LENGTH_SPR ** 3\n",
        "num_samples = 100\n",
        "\n",
        "epoch = 0\n",
        "g_ij = np.zeros((N_SP_SPR, N_SP_SPR))\n",
        "norm_sums_ij = np.zeros_like(g_ij, dtype=np.float64)\n",
        "\n",
        "folder_filename = f'surfacePatternRecognition_{time.strftime(\"%Y%m%d-%H%M%S\")}'\n",
        "!mkdir $folder_filename\n",
        "with open(f'{folder_filename}/hyperparameters.txt', 'w') as f:\n",
        "  f.write(f'parallel_proposals_per_epoch: {parallel_proposals_per_epoch}\\n')\n",
        "  f.write(f'learning_rate: {learning_rate}\\n')"
      ],
      "metadata": {
        "id": "gSicxp5QCPZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing function"
      ],
      "metadata": {
        "id": "wcSLQZJjMwz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(g_ij):\n",
        "  lattice = test_lattice()\n",
        "\n",
        "  free_pos = np.ones((LATTICE_LENGTH_SPR,\n",
        "                      LATTICE_LENGTH_SPR,\n",
        "                      LATTICE_LENGTH_SPR), dtype=bool)\n",
        "\n",
        "  # Species 0-1 are not free\n",
        "  mask = np.isin(lattice, [1, 2])\n",
        "  free_pos[mask] = False\n",
        "\n",
        "  lattice, _, _, energies = mcmc(lattice_batch = lattice,\n",
        "                                 num_parallel_proposals = parallel_proposals_per_epoch,\n",
        "                                 num_samples = num_samples,\n",
        "                                 burn_in = parallel_proposals_per_epoch//2,\n",
        "                                 num_species = N_SP_SPR,\n",
        "                                 g_ij_batch = g_ij,\n",
        "                                 free_pos_batch = free_pos,\n",
        "                                 kT_high_batch = 10.0,\n",
        "                                 kT_low_batch = 1.0,\n",
        "                                 canonical = True,\n",
        "                                 ranged = True)\n",
        "\n",
        "  plot_lattice(lattice, N_SP_SPR, color_dict=COLOR_DICT_SPR)\n",
        "  plot_energies(energies,\n",
        "                parallel_proposals_per_epoch,\n",
        "                parallel_proposals_per_epoch//2,\n",
        "                num_samples)"
      ],
      "metadata": {
        "id": "EgPSEDgnM157"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training epoch function"
      ],
      "metadata": {
        "id": "g7j5twj8wOfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_epoch(g_ij, learning_rate, adagrad=False, norm_sums_ij=None):\n",
        "  dw = np.zeros_like(g_ij)\n",
        "\n",
        "  # Wake phase\n",
        "  lattice = training_distribution()\n",
        "\n",
        "  free_pos = np.ones((LATTICE_LENGTH_SPR,\n",
        "                      LATTICE_LENGTH_SPR,\n",
        "                      LATTICE_LENGTH_SPR), dtype=bool)\n",
        "\n",
        "  # Species 0-4 are not free\n",
        "  mask = np.isin(lattice, [0, 1, 2, 3, 4])\n",
        "  free_pos[mask] = False\n",
        "\n",
        "  lattice, n_ij, _, energies = mcmc(lattice_batch = lattice,\n",
        "                                    num_parallel_proposals = parallel_proposals_per_epoch,\n",
        "                                    num_samples = num_samples,\n",
        "                                    burn_in = parallel_proposals_per_epoch//2,\n",
        "                                    num_species = N_SP_SPR,\n",
        "                                    g_ij_batch = g_ij,\n",
        "                                    free_pos_batch = free_pos,\n",
        "                                    kT_high_batch = 10.0,\n",
        "                                    kT_low_batch = 1.0,\n",
        "                                    canonical = True,\n",
        "                                    ranged = True)\n",
        "\n",
        "  dw -= n_ij\n",
        "\n",
        "  # Sleep phase\n",
        "  lattice = test_lattice()\n",
        "  free_pos = np.ones((LATTICE_LENGTH_SPR,\n",
        "                      LATTICE_LENGTH_SPR,\n",
        "                      LATTICE_LENGTH_SPR), dtype=bool)\n",
        "\n",
        "  # Species 0-1 are always clamped\n",
        "  mask = np.isin(lattice, [1, 2])\n",
        "  free_pos[mask] = False\n",
        "\n",
        "  lattice, n_ij, _, energies = mcmc(lattice_batch = lattice,\n",
        "                                    num_parallel_proposals =parallel_proposals_per_epoch,\n",
        "                                    num_samples = num_samples,\n",
        "                                    burn_in = parallel_proposals_per_epoch//2,\n",
        "                                    num_species = N_SP_SPR,\n",
        "                                    g_ij_batch = g_ij,\n",
        "                                    free_pos_batch = free_pos,\n",
        "                                    kT_high_batch = 10.0,\n",
        "                                    kT_low_batch = 1.0,\n",
        "                                    canonical = True,\n",
        "                                    ranged = True)\n",
        "\n",
        "  dw += n_ij\n",
        "\n",
        "  if adagrad:\n",
        "    norm_sums_ij += dw ** 2\n",
        "    g_ij += learning_rate * dw / np.sqrt(norm_sums_ij + 1e-8)\n",
        "  else:\n",
        "    g_ij += learning_rate * dw\n",
        "  return g_ij, norm_sums_ij"
      ],
      "metadata": {
        "id": "YIySWQgjy5V-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training"
      ],
      "metadata": {
        "id": "Cc_LF0CJ2-Zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(max_epochs):\n",
        "  g_ij, norm_sums_ij = training_epoch(g_ij,\n",
        "                                      learning_rate,\n",
        "                                      adagrad=True,\n",
        "                                      norm_sums_ij=norm_sums_ij)\n",
        "\n",
        "  if epoch % save_frequency == 0:\n",
        "    clear_output(wait=True)\n",
        "    print(f'Epoch: {epoch}')\n",
        "    np.save(f'{folder_filename}/g_ij_{epoch}', g_ij)\n",
        "    test(g_ij)\n",
        "    plt.imshow(g_ij)\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "  epoch = epoch + 1"
      ],
      "metadata": {
        "id": "gmEo0oG_3j9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Paper-reported parameters and plotting\n",
        "Running this will overwrite trained $G_{ij}$"
      ],
      "metadata": {
        "id": "RrKmlQ2ZkOBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_ij = np.load('spr_g_ij.npy')\n",
        "plot_g_ij(g_ij)"
      ],
      "metadata": {
        "id": "KspWlyDPk1_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(g_ij)"
      ],
      "metadata": {
        "id": "RVfUQ8ZwlCQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Red and blue species heatmaps"
      ],
      "metadata": {
        "id": "5qVDataGoF9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_trials = 100\n",
        "\n",
        "lattices = []\n",
        "\n",
        "for _ in range(num_trials):\n",
        "  lattice = test_lattice()\n",
        "  lattices.append(lattice)\n",
        "\n",
        "free_pos = np.ones((LATTICE_LENGTH_SPR,\n",
        "                    LATTICE_LENGTH_SPR,\n",
        "                    LATTICE_LENGTH_SPR), dtype=bool)\n",
        "\n",
        "# Species 0-1 are not free\n",
        "mask = np.isin(lattice, [1, 2])\n",
        "free_pos[mask] = False\n",
        "\n",
        "free_pos_s = np.array([free_pos] * num_trials)\n",
        "\n",
        "lattices, _, _, energies = mcmc(lattice_batch = lattices,\n",
        "                                num_parallel_proposals = parallel_proposals_per_epoch,\n",
        "                                num_samples = num_samples,\n",
        "                                burn_in = parallel_proposals_per_epoch//2,\n",
        "                                num_species = N_SP_SPR,\n",
        "                                g_ij_batch = g_ij,\n",
        "                                free_pos_batch = free_pos_s,\n",
        "                                kT_high_batch = 10.0,\n",
        "                                kT_low_batch = 1.0,\n",
        "                                canonical = True,\n",
        "                                ranged = True)"
      ],
      "metadata": {
        "id": "HvGmf4ZVoPKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "red_heatmaps = []\n",
        "blue_heatmaps = []\n",
        "for lattice in lattices:\n",
        "    red_lattice = np.copy(lattice)\n",
        "    for i in range(1, N_SP_SPR):\n",
        "        if i != 3:\n",
        "            red_lattice[red_lattice == i] = 0\n",
        "        else:\n",
        "            red_lattice[red_lattice == i] = 1\n",
        "    blue_lattice = np.copy(lattice)\n",
        "    for i in range(1, N_SP_SPR):\n",
        "        if i != 4:\n",
        "            blue_lattice[blue_lattice == i] = 0\n",
        "        else:\n",
        "            blue_lattice[blue_lattice == i] = 1\n",
        "    red_heatmap = np.sum(red_lattice, axis=2)\n",
        "    blue_heatmap = np.sum(blue_lattice, axis=2)\n",
        "    red_heatmaps.append(red_heatmap)\n",
        "    blue_heatmaps.append(blue_heatmap)\n",
        "\n",
        "red_heatmaps = np.mean(red_heatmaps, axis=0)\n",
        "red_heatmaps = np.transpose(red_heatmaps)\n",
        "blue_heatmaps = np.mean(blue_heatmaps, axis=0)\n",
        "blue_heatmaps = np.transpose(blue_heatmaps)\n",
        "\n",
        "plt.imshow(red_heatmaps, cmap='hot')\n",
        "plt.title('Red species heatmap')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(blue_heatmaps, cmap='hot')\n",
        "plt.title('Blue species heatmap')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "otpe1_CCoJdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Recognition of concentration profiles mapped from MNIST digits"
      ],
      "metadata": {
        "id": "38DO1KfG5TER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Plotting functions for MNIST tests"
      ],
      "metadata": {
        "id": "GcM9ep436LQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def image_2d_arrays(arr, titles=None, numbers=True, figsizeparam=4):\n",
        "    if titles is None:\n",
        "        titles = ['']*len(arr)\n",
        "    n = len(arr)\n",
        "    fig, axs = plt.subplots(1, n, figsize=(n*figsizeparam, figsizeparam))\n",
        "    #Set range for color scale to the min and max over all arrays\n",
        "    all_elements = np.concatenate([ar.flatten() for ar in arr])\n",
        "    vmin = np.min(all_elements)\n",
        "    vmax = np.max(all_elements)\n",
        "    for i in range(n):\n",
        "        axs[i].set_title(titles[i])\n",
        "        axs[i].imshow(arr[i], vmin=vmin, vmax=vmax, cmap='viridis')\n",
        "         # Add array's float values to imshow\n",
        "        ax = axs[i]\n",
        "        if numbers:\n",
        "            for (j,k),label in np.ndenumerate(arr[i]):\n",
        "                ax.text(k,j,np.round(label,2),ha='center',va='center',color='white',path_effects=[pe.withStroke(linewidth=2, foreground=\"black\")])\n",
        "    #Hide tick marks\n",
        "    for ax in axs:\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def list_plot(arr):\n",
        "    plt.plot(arr)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def image_2d_array(arr, title=None, numbers=False, figsize=(12,12)):\n",
        "    if title is None:\n",
        "        title = ''\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "    ax.set_title(title)\n",
        "    ax.imshow(arr, cmap='viridis')\n",
        "    # Add array's float values to imshow\n",
        "    if numbers:\n",
        "        for (i,j),label in np.ndenumerate(arr):\n",
        "            ax.text(j,i,np.round(label,2),ha='center',va='center',color='white', path_effects=[pe.withStroke(linewidth=2, foreground=\"black\")])\n",
        "    #If numbers is false, plot max and min as key to the right of the plot\n",
        "    else:\n",
        "        ax.text(1.1,0.5,np.round(np.max(arr),2),ha='center',va='center', transform=ax.transAxes)\n",
        "        ax.text(1.1,0.1,np.round(np.min(arr),2),ha='center',va='center', transform=ax.transAxes)\n",
        "    #Hide tick marks\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "zpWW5mqZ6Jwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Globals and helper functions"
      ],
      "metadata": {
        "id": "H_a4dXvh6qbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 28 * 28 = 784 species, 10 classes, round up to 1000 for 206 hidden species, total 1000 species\n",
        "# 64^3 = 262144 lattice, about 262 positions per species if divvied up equally\n",
        "\n",
        "N_SP_DIGIT = 28*28\n",
        "N_SP_CLASS = 10\n",
        "N_SP_HIDDEN = 1000 - N_SP_DIGIT - N_SP_CLASS\n",
        "N_SP_MNIST = N_SP_DIGIT + N_SP_CLASS + N_SP_HIDDEN\n",
        "LATTICE_LENGTH_MNIST = 32\n",
        "# Dimensions for plotting\n",
        "DIGIT_DIMS = (28,28)\n",
        "CLASS_DIMS = (1,10)\n",
        "HIDDEN_DIMS = (2,103)\n",
        "DIGIT_SHARE = LATTICE_LENGTH_MNIST**3 * N_SP_DIGIT/1000\n",
        "CLASS_SHARE = LATTICE_LENGTH_MNIST**3 * N_SP_CLASS/1000\n",
        "HIDDEN_SHARE = LATTICE_LENGTH_MNIST**3 * N_SP_HIDDEN/1000\n",
        "\n",
        "TRAINING_STEPS = 10000\n",
        "SWAPS = LATTICE_LENGTH_MNIST**3 * 64\n",
        "SWAPS_PER_STEP = LATTICE_LENGTH_MNIST**3 / 4**3\n",
        "STEPS = SWAPS // SWAPS_PER_STEP\n",
        "burn_in_STEPS = 10000\n",
        "COLLECTION_STEPS = 10000\n",
        "SAMPLES_TO_COLLECT = 100\n",
        "SAMPLERATE = int(COLLECTION_STEPS // SAMPLES_TO_COLLECT)\n",
        "LEARNINGRATE = 0.025\n",
        "BATCHSIZE = 1"
      ],
      "metadata": {
        "id": "tGt8WgIR6w-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_field():\n",
        "    return np.random.randint(N_SP_MNIST, size=(LATTICE_LENGTH_MNIST, LATTICE_LENGTH_MNIST, LATTICE_LENGTH_MNIST)).astype(np.int32)\n",
        "\n",
        "\n",
        "def shuffle_field(field):\n",
        "  shuffled_field = np.copy(field).flatten()\n",
        "  np.random.shuffle(shuffled_field)\n",
        "  return shuffled_field.reshape((LATTICE_LENGTH_MNIST, LATTICE_LENGTH_MNIST, LATTICE_LENGTH_MNIST))\n",
        "\n",
        "\n",
        "def shuffled_input_field(v):\n",
        "  return shuffle_field(np.reshape(np.repeat(np.arange(N_SP_MNIST), v), (LATTICE_LENGTH_MNIST, LATTICE_LENGTH_MNIST, LATTICE_LENGTH_MNIST)))\n",
        "\n",
        "\n",
        "# Turns MNIST data into a vector of counts for the lattice\n",
        "# The training version of this function has all class-count share in the correct class...\n",
        "def digit_to_counts_training(digit, classification):\n",
        "  # Digit counts should be normalized\n",
        "  digitcounts = digit * (DIGIT_SHARE // np.sum(digit))\n",
        "  classcounts = np.zeros(N_SP_CLASS, dtype=np.int32)\n",
        "  classcounts[classification] = int(CLASS_SHARE)\n",
        "  if N_SP_HIDDEN != 0:\n",
        "    hiddens = np.ones(N_SP_HIDDEN, dtype=np.int32) * int(HIDDEN_SHARE // N_SP_HIDDEN)\n",
        "  counts = np.concatenate((digitcounts, classcounts, hiddens)).astype(np.int32)\n",
        "  # If total count is not LATTICE_LENGTH^3, add random molecule counts to make it so\n",
        "  if np.sum(counts) < LATTICE_LENGTH_MNIST**3:\n",
        "    for _ in range(LATTICE_LENGTH_MNIST**3 - np.sum(counts)):\n",
        "      counts[np.random.randint(N_SP_MNIST)] += 1\n",
        "  return counts\n",
        "\n",
        "\n",
        "# ... while the test version has the class counts split between the classes\n",
        "def digit_to_counts_test(digit):\n",
        "  # Digits counts should be normalized\n",
        "  digitcounts = digit * (DIGIT_SHARE // np.sum(digit))\n",
        "  classcounts = np.ones(N_SP_CLASS, dtype=np.int32) * (CLASS_SHARE // N_SP_CLASS)\n",
        "  if N_SP_HIDDEN != 0:\n",
        "    hiddens = np.ones(N_SP_HIDDEN, dtype=np.int32) * int(HIDDEN_SHARE // N_SP_HIDDEN)\n",
        "  counts = np.concatenate((digitcounts, classcounts, hiddens)).astype(np.int32)\n",
        "  # If total count is not LATTICE_LENGTH^3, add random molecule counts to make it so\n",
        "  if np.sum(counts) < LATTICE_LENGTH_MNIST**3:\n",
        "    for _ in range(LATTICE_LENGTH_MNIST ** 3 - np.sum(counts)):\n",
        "      counts[np.random.randint(N_SP_MNIST)] += 1\n",
        "  return counts\n",
        "\n",
        "\n",
        "def classification_test_counts(classification):\n",
        "  #Uniformly distribute digit counts\n",
        "  digitcounts = np.ones(N_SP_DIGIT, dtype=np.int32) * (DIGIT_SHARE // N_SP_DIGIT)\n",
        "  classcounts = np.zeros(N_SP_CLASS)\n",
        "  classcounts[classification] = int(CLASS_SHARE)\n",
        "  if N_SP_HIDDEN != 0:\n",
        "    hiddens = np.ones(N_SP_HIDDEN, dtype=np.int32) * (HIDDEN_SHARE // N_SP_HIDDEN)\n",
        "  counts = np.concatenate((digitcounts, classcounts, hiddens)).astype(np.int32)\n",
        "  if np.sum(counts) < LATTICE_LENGTH_MNIST**3:\n",
        "    for _ in range(LATTICE_LENGTH_MNIST**3 - np.sum(counts)):\n",
        "      counts[np.random.randint(N_SP_MNIST)] += 1\n",
        "  return counts"
      ],
      "metadata": {
        "id": "fp5Rm5pWK34L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training initialization"
      ],
      "metadata": {
        "id": "yDKVPsAQboc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 10000\n",
        "parallel_proposals_per_epoch = 20000\n",
        "save_frequency = 10\n",
        "learning_rate = 0.025\n",
        "num_samples = 10\n",
        "\n",
        "epoch = 0\n",
        "g_ij = np.zeros((N_SP_MNIST, N_SP_MNIST))\n",
        "g_i = np.zeros(N_SP_MNIST)\n",
        "norm_sums_ij = np.zeros_like(g_ij, dtype=np.float64)\n",
        "norm_sums_i = np.zeros_like(g_i, dtype=np.float64)\n",
        "\n",
        "folder_filename = f'mnistRecognition_{time.strftime(\"%Y%m%d-%H%M%S\")}'\n",
        "\n",
        "!mkdir $folder_filename\n",
        "with open(f'{folder_filename}/hyperparameters.txt', 'w') as f:\n",
        "  f.write(f'parallel_proposals_per_epoch: {parallel_proposals_per_epoch}\\n')\n",
        "  f.write(f'learning_rate: {learning_rate}\\n')"
      ],
      "metadata": {
        "id": "lspUzs-V-oOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import MNIST digits"
      ],
      "metadata": {
        "id": "E0PKuLdx5k2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "#Import MNIST data\n",
        "def import_mnist(filename):\n",
        "    with open(filename, newline='') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        rows = []\n",
        "        for row in reader:\n",
        "            rows.append(row)\n",
        "            #First and last values have mathematica opening and closing brackets respectively\n",
        "            rows[-1][0] = rows[-1][0][1:]\n",
        "            rows[-1][-1] = rows[-1][-1][:-1]\n",
        "        #Convert to numpy array\n",
        "        rows = np.array(rows)\n",
        "        #Convert to float\n",
        "        rows = rows.astype(np.float64)\n",
        "        return rows\n",
        "\n",
        "mnistTrain = []\n",
        "mnistTest = []\n",
        "for i in range(10):\n",
        "    mnistTrain.append(import_mnist(f'mnistTrain{i}.csv'))\n",
        "    mnistTest.append(import_mnist(f'mnistTest{i}.csv'))"
      ],
      "metadata": {
        "id": "WaAW6jPe5fcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####MNIST data sanity check"
      ],
      "metadata": {
        "id": "YainyyYm5-kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check MNIST data\n",
        "image_2d_array(np.reshape(mnistTrain[0][np.random.randint(len(mnistTrain[0]))], DIGIT_DIMS), title='Random training digit', numbers=True)\n",
        "image_2d_array(np.reshape(mnistTest[9][np.random.randint(len(mnistTest[9]))], DIGIT_DIMS), title='Random test digit', numbers=True)"
      ],
      "metadata": {
        "id": "PwEEKlXa6A3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training epoch function"
      ],
      "metadata": {
        "id": "GJa1EMOncVgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_epoch(g_ij, g_i, adagrad=False, norm_sums_ij=None, norm_sums_i=None):\n",
        "  dw = np.zeros((N_SP_MNIST, N_SP_MNIST))\n",
        "  db = np.zeros(N_SP_MNIST)\n",
        "\n",
        "  lattices = []\n",
        "  for i in range(N_SP_CLASS):\n",
        "    lattices.append(shuffled_input_field(digit_to_counts_training(mnistTrain[i][np.random.randint(len(mnistTrain[i]))], i)))\n",
        "  # Wake phase; only hidden species are free\n",
        "  free_species = np.concatenate((np.zeros(N_SP_DIGIT, dtype=bool),\n",
        "                                np.zeros(N_SP_CLASS, dtype=bool),\n",
        "                                np.ones(N_SP_HIDDEN, dtype=bool)))\n",
        "  lattices, n_ijs, n_is, _ = mcmc(lattice_batch = lattices,\n",
        "                                  num_parallel_proposals = parallel_proposals_per_epoch,\n",
        "                                  num_samples = num_samples,\n",
        "                                  burn_in = parallel_proposals_per_epoch//2,\n",
        "                                  num_species = N_SP_MNIST,\n",
        "                                  g_ij_batch = g_ij,\n",
        "                                  g_i_batch = g_i,\n",
        "                                  free_species_batch = free_species,\n",
        "                                  hybrid = True)\n",
        "\n",
        "  for i in range(N_SP_CLASS):\n",
        "    dw -= n_ijs[i]\n",
        "    db -= n_is[i]\n",
        "\n",
        "  # Sleep phase\n",
        "  lattices = []\n",
        "  for i in range(N_SP_CLASS):\n",
        "    lattices.append(random_field())\n",
        "  free_species = np.concatenate((np.ones(N_SP_DIGIT, dtype=bool),\n",
        "                                np.ones(N_SP_CLASS, dtype=bool),\n",
        "                                np.ones(N_SP_HIDDEN, dtype=bool)))\n",
        "  lattices, n_ijs, n_is, _ = mcmc(lattice_batch = lattices,\n",
        "                                  num_parallel_proposals =parallel_proposals_per_epoch,\n",
        "                                  num_samples = num_samples,\n",
        "                                  burn_in = parallel_proposals_per_epoch//2,\n",
        "                                  num_species = N_SP_MNIST,\n",
        "                                  g_ij_batch = g_ij,\n",
        "                                  g_i_batch = g_i,\n",
        "                                  free_species_batch = free_species,\n",
        "                                  hybrid = True)\n",
        "\n",
        "  for i in range(N_SP_CLASS):\n",
        "    dw += n_ijs[i]\n",
        "    db += n_is[i]\n",
        "\n",
        "  if adagrad:\n",
        "    norm_sums_ij += dw ** 2\n",
        "    g_ij += learning_rate * dw / np.sqrt(norm_sums_ij + 1e-8)\n",
        "    norm_sums_i += db ** 2\n",
        "    g_i += learning_rate * db / np.sqrt(norm_sums_i + 1e-8)\n",
        "  else:\n",
        "    g_ij += learning_rate * dw\n",
        "    g_i += learning_rate * db\n",
        "\n",
        "  return g_ij, g_i, norm_sums_ij, norm_sums_i"
      ],
      "metadata": {
        "id": "BvAs4j7_cXzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing function"
      ],
      "metadata": {
        "id": "EAOr9bwfysZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def digit_clamp_test(g_ij, g_i):\n",
        "  lattices = []\n",
        "  for i in range(N_SP_CLASS):\n",
        "    lattices.append(shuffled_input_field(digit_to_counts_test(mnistTest[i][np.random.randint(len(mnistTest[i]))])))\n",
        "  init_lattices = np.copy(lattices)\n",
        "  free_species = np.concatenate((np.zeros(N_SP_DIGIT, dtype=bool),\n",
        "                                 np.ones(N_SP_CLASS, dtype=bool),\n",
        "                                 np.ones(N_SP_HIDDEN, dtype=bool)))\n",
        "  lattices, n_ijs, n_is, energies = mcmc(lattice_batch = lattices,\n",
        "                                         num_parallel_proposals = parallel_proposals_per_epoch,\n",
        "                                         num_samples = num_samples,\n",
        "                                         burn_in = parallel_proposals_per_epoch//2,\n",
        "                                         num_species = N_SP_MNIST,\n",
        "                                         g_ij_batch = g_ij,\n",
        "                                         g_i_batch = g_i,\n",
        "                                         free_species_batch = free_species,\n",
        "                                         hybrid = True)\n",
        "  return n_ijs, n_is, energies, init_lattices, lattices"
      ],
      "metadata": {
        "id": "Dy_a4vxHyr83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training"
      ],
      "metadata": {
        "id": "mPayxz1L-Lgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(max_epochs):\n",
        "  g_ij, g_i, norm_sums_ij, norm_sums_i = training_epoch(g_ij,\n",
        "                                                        g_i,\n",
        "                                                        adagrad=True,\n",
        "                                                        norm_sums_ij=norm_sums_ij,\n",
        "                                                        norm_sums_i=norm_sums_i)\n",
        "  epoch = epoch + 1\n",
        "  if i % save_frequency == 0:\n",
        "    clear_output(wait=True)\n",
        "    print(f'Epoch: {epoch}')\n",
        "    np.save(f'{folder_filename}/g_ij_{i}', g_ij)\n",
        "    np.save(f'{folder_filename}/g_i_{i}', g_i)\n",
        "    n_ijs, n_is, energies, init_lattices, lattices = digit_clamp_test(g_ij, g_i)\n",
        "    for j in range(N_SP_CLASS):\n",
        "      print(f'Class: {j}')\n",
        "      image_2d_array(np.reshape(n_is[j][:N_SP_DIGIT], DIGIT_DIMS), numbers=True)\n",
        "      image_2d_array(np.reshape(n_is[j][N_SP_DIGIT:N_SP_DIGIT+N_SP_CLASS], CLASS_DIMS), numbers=True)\n",
        "      image_2d_array(np.reshape(n_is[j][N_SP_DIGIT+N_SP_CLASS:N_SP_MNIST], HIDDEN_DIMS), numbers=True, figsize=(36,36))\n",
        "      plot_energies(energies[j],\n",
        "                    parallel_proposals_per_epoch,\n",
        "                    parallel_proposals_per_epoch//2,\n",
        "                    num_samples)"
      ],
      "metadata": {
        "id": "WKOHFjaT-OY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Paper-reported parameters\n",
        "Running this will overwrite trained $G_{ij}$, $G_i$"
      ],
      "metadata": {
        "id": "zGSke1qPKPza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_ij = np.load('mnist_g_ij.npy')\n",
        "plot_g_ij(g_ij)\n",
        "g_i = np.load('mnist_g_i.npy')\n",
        "plot_g_ij(np.reshape(g_i, (10, 100)))"
      ],
      "metadata": {
        "id": "ZhvAulcdKR47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_ijs, n_is, energies, init_lattices, lattices = digit_clamp_test(g_ij, g_i)\n",
        "for j in range(N_SP_CLASS):\n",
        "  print(f'Class: {j}')\n",
        "  image_2d_array(np.reshape(n_is[j][:N_SP_DIGIT], DIGIT_DIMS), numbers=True)\n",
        "  image_2d_array(np.reshape(n_is[j][N_SP_DIGIT:N_SP_DIGIT+N_SP_CLASS], CLASS_DIMS), numbers=True)\n",
        "  image_2d_array(np.reshape(n_is[j][N_SP_DIGIT+N_SP_CLASS:N_SP_MNIST], HIDDEN_DIMS), numbers=True, figsize=(36,36))\n",
        "  plot_energies(energies[j],\n",
        "                parallel_proposals_per_epoch,\n",
        "                parallel_proposals_per_epoch//2,\n",
        "                num_samples)"
      ],
      "metadata": {
        "id": "BJmBtSalNGxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Confusion Matrix"
      ],
      "metadata": {
        "id": "rdMvWf5jZ8uI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classification_test(g_ij, g_i, num_tests):\n",
        "  confusion_matrix = np.zeros((N_SP_CLASS, N_SP_CLASS))\n",
        "  sums_matrix = np.zeros((N_SP_CLASS, N_SP_CLASS))\n",
        "  for j in range(num_tests):\n",
        "    lattices = []\n",
        "    for i in range(N_SP_CLASS):\n",
        "      lattices.append(shuffled_input_field((digit_to_counts_test(mnistTest[i][j]))))\n",
        "    free_species = np.concatenate((np.zeros(N_SP_DIGIT, dtype=bool),\n",
        "                                     np.ones(N_SP_CLASS, dtype=bool),\n",
        "                                     np.ones(N_SP_HIDDEN, dtype=bool)))\n",
        "    lattices, n_ijs, n_is, _ = mcmc(lattice_batch = lattices,\n",
        "                                    num_parallel_proposals = parallel_proposals_per_epoch,\n",
        "                                    num_samples = num_samples,\n",
        "                                    burn_in = parallel_proposals_per_epoch//2,\n",
        "                                    num_species = N_SP_MNIST,\n",
        "                                    g_ij_batch = g_ij,\n",
        "                                    g_i_batch = g_i,\n",
        "                                    free_species_batch = free_species,\n",
        "                                    hybrid = True)\n",
        "    for i in range(N_SP_CLASS):\n",
        "      confusion_matrix[i, np.argmax(n_is[i][N_SP_DIGIT:N_SP_DIGIT+N_SP_CLASS])] += 1\n",
        "      sums_matrix[i, :] += n_is[i][N_SP_DIGIT:N_SP_DIGIT+N_SP_CLASS]\n",
        "  return confusion_matrix, sums_matrix"
      ],
      "metadata": {
        "id": "C__BVpqJZ_JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tests = 10\n",
        "\n",
        "confusion_matrix, sums_matrix = classification_test(g_ij, g_i, num_tests)\n",
        "\n",
        "accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "CDe0fvEHdoil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(confusion_matrix, cmap='gray_r')\n",
        "plt.xticks(np.arange(N_SP_CLASS))\n",
        "plt.yticks(np.arange(N_SP_CLASS))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.colorbar()\n",
        "plt.title(f'Confusion matrix ({num_tests} test samples per class)')\n",
        "plt.clim(0, num_tests)\n",
        "plt.savefig('confusion_matrix_100tests.svg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KqTfCfkwd0mQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}